{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Random Forest (Floresta Aleatória)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict  # Fix: replaced 'sklearn.cross_validation' with 'sklearn.model_selection'\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu = pd.read_csv('xAPI-Edu-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender NationalITy PlaceofBirth     StageID GradeID SectionID Topic  \\\n",
       "0      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "1      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "2      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "3      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "4      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "\n",
       "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "2        F   Father           10                 7                  0   \n",
       "3        F   Father           30                25                  5   \n",
       "4        F   Father           40                50                 12   \n",
       "\n",
       "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "2          30                    No                      Bad   \n",
       "3          35                    No                      Bad   \n",
       "4          50                    No                      Bad   \n",
       "\n",
       "  StudentAbsenceDays Class  \n",
       "0            Under-7     M  \n",
       "1            Under-7     M  \n",
       "2            Above-7     L  \n",
       "3            Above-7     L  \n",
       "4            Above-7     M  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando as distribuições de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    211\n",
       "H    142\n",
       "L    127\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os registros nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                      0\n",
       "NationalITy                 0\n",
       "PlaceofBirth                0\n",
       "StageID                     0\n",
       "GradeID                     0\n",
       "SectionID                   0\n",
       "Topic                       0\n",
       "Semester                    0\n",
       "Relation                    0\n",
       "raisedhands                 0\n",
       "VisITedResources            0\n",
       "AnnouncementsView           0\n",
       "Discussion                  0\n",
       "ParentAnsweringSurvey       0\n",
       "ParentschoolSatisfaction    0\n",
       "StudentAbsenceDays          0\n",
       "Class                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codificando os atributos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = df_edu\n",
    "Cat_Colums = Features.dtypes.pipe(lambda Features: Features[Features=='object']).index\n",
    "for col in Cat_Colums:\n",
    "    label = LabelEncoder()\n",
    "    Features[col] = label.fit_transform(Features[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  NationalITy  PlaceofBirth  StageID  GradeID  SectionID  Topic  \\\n",
       "0       1            4             4        2        1          0      7   \n",
       "1       1            4             4        2        1          0      7   \n",
       "2       1            4             4        2        1          0      7   \n",
       "3       1            4             4        2        1          0      7   \n",
       "4       1            4             4        2        1          0      7   \n",
       "\n",
       "   Semester  Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0         0         0           15                16                  2   \n",
       "1         0         0           20                20                  3   \n",
       "2         0         0           10                 7                  0   \n",
       "3         0         0           30                25                  5   \n",
       "4         0         0           40                50                 12   \n",
       "\n",
       "   Discussion  ParentAnsweringSurvey  ParentschoolSatisfaction  \\\n",
       "0          20                      1                         1   \n",
       "1          25                      1                         1   \n",
       "2          30                      0                         0   \n",
       "3          35                      0                         0   \n",
       "4          50                      0                         0   \n",
       "\n",
       "   StudentAbsenceDays  Class  \n",
       "0                   1      2  \n",
       "1                   1      2  \n",
       "2                   0      1  \n",
       "3                   0      1  \n",
       "4                   0      2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando os dados e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_edu.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df_edu['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest vs Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf = RandomForestClassifier(random_state=1,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_random = cross_val_predict(random_clf, dataset, classes, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65       142\n",
      "           1       0.77      0.78      0.77       127\n",
      "           2       0.63      0.63      0.63       211\n",
      "\n",
      "    accuracy                           0.67       480\n",
      "   macro avg       0.68      0.68      0.68       480\n",
      "weighted avg       0.67      0.67      0.67       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_tree = cross_val_predict(tree_clf,dataset,classes,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55       142\n",
      "           1       0.74      0.68      0.70       127\n",
      "           2       0.54      0.49      0.52       211\n",
      "\n",
      "    accuracy                           0.57       480\n",
      "   macro avg       0.59      0.59      0.59       480\n",
      "weighted avg       0.58      0.57      0.58       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_edu.drop('Class',axis=1),df_edu['Class'],test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_random_forest(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        rf = RandomForestClassifier(n_estimators=100,random_state=1)\n",
    "    else: \n",
    "        rf = RandomForestClassifier(n_estimators=100,random_state=1, max_depth=maxdepth)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_score = rf.score(X_train, y_train)\n",
    "    test_score = rf.score(X_test, y_test)\n",
    "    return train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training score       Testing score       \n",
      "-----      --------------       -------------       \n",
      "2         (0.75, 0.6180555555555556) \n",
      "3         (0.8244047619047619, 0.6805555555555556) \n",
      "4         (0.8720238095238095, 0.7152777777777778) \n",
      "10         (1.0, 0.7569444444444444) \n",
      "15         (1.0, 0.7986111111111112) \n",
      "Full         (1.0, 0.7986111111111112) \n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
    "print('{:1}         {} '.format(2,str(compara_modelos_random_forest(2))))\n",
    "print('{:1}         {} '.format(3,str(compara_modelos_random_forest(3))))\n",
    "print('{:1}         {} '.format(4,str(compara_modelos_random_forest(4))))\n",
    "print('{:1}         {} '.format(10,str(compara_modelos_random_forest(10))))\n",
    "print('{:1}         {} '.format(15,str(compara_modelos_random_forest(15))))\n",
    "print('{:1}         {} '.format('Full',str(compara_modelos_random_forest(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_decision_tree(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        df = DecisionTreeClassifier(random_state=1)\n",
    "    else: \n",
    "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
    "    df.fit(X_train, y_train)\n",
    "    train_score = df.score(X_train, y_train)\n",
    "    test_score = df.score(X_test, y_test)\n",
    "    return train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training score       Testing score       \n",
      "-----      --------------       -------------       \n",
      "2         (0.6398809523809523, 0.6805555555555556) \n",
      "3         (0.7321428571428571, 0.7013888888888888) \n",
      "4         (0.7916666666666666, 0.7430555555555556) \n",
      "10         (0.9910714285714286, 0.6875) \n",
      "15         (1.0, 0.6944444444444444) \n",
      "Full         (1.0, 0.6944444444444444) \n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
    "print('{:1}         {} '.format(2,str(compara_modelos_decision_tree(2))))\n",
    "print('{:1}         {} '.format(3,str(compara_modelos_decision_tree(3))))\n",
    "print('{:1}         {} '.format(4,str(compara_modelos_decision_tree(4))))\n",
    "print('{:1}         {} '.format(10,str(compara_modelos_decision_tree(10))))\n",
    "print('{:1}         {} '.format(15,str(compara_modelos_decision_tree(15))))\n",
    "print('{:1}         {} '.format('Full',str(compara_modelos_decision_tree(0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning do Modelo para Garantir o Melhor Desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como encontrar os melhores valores para os parametros do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(\n",
    "n_estimators=?,\n",
    "criterion='gini' ou 'entropy',\n",
    "max_depth=?,\n",
    "min_samples_split=?,\n",
    "min_samples_leaf=?\n",
    ") ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV para testes de Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores de estimators ou quantidade de árvores da floresta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_estimators = [10, 20, 50, 100, 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para o critério de divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_criterion = ['gini','entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para a profundidade máxima de cada árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_max_depth = [10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para os parametros min_samples_split e min_samples_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_min_samples_split = [2, 5, 10,15]\n",
    "valores_min_samples_leaf = [1, 5, 10,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define um dicionário que recebe as listas de parâmetros e valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = dict(n_estimators=valores_estimators,\n",
    "                       criterion=valores_criterion,\n",
    "                       max_depth=valores_max_depth,\n",
    "                       min_samples_split=valores_min_samples_split,\n",
    "                       min_samples_leaf=valores_min_samples_leaf \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dicionário com os parametros que serão utilizados no grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 20, 50, 100, 150],\n",
       " 'criterion': ['gini', 'entropy'],\n",
       " 'max_depth': [10, 20, 50, 100],\n",
       " 'min_samples_split': [2, 5, 10, 15],\n",
       " 'min_samples_leaf': [1, 5, 10, 15]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametros_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instancia o GridSearch com o modelo a ser utilizado, parametros, número de folds e scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(rf, parametros_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplica o GridSearch passando as features e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 50, 100],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10, 15],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100, 150]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 50, 100],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 5, 10, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10, 15],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100, 150]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 50, 100],\n",
       "                         'min_samples_leaf': [1, 5, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 10, 15],\n",
       "                         'n_estimators': [10, 20, 50, 100, 150]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(df_edu.drop('Class',axis=1),df_edu['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprime os scores por combinações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01282816, 0.02592082, 0.05583439, 0.10479078, 0.15608883,\n",
       "        0.01268258, 0.02612619, 0.05276866, 0.1008903 , 0.15879536,\n",
       "        0.00625939, 0.02411432, 0.05326266, 0.10616689, 0.15594702,\n",
       "        0.01404262, 0.01901755, 0.04786553, 0.11245074, 0.16351433,\n",
       "        0.0108439 , 0.02327809, 0.05396833, 0.10568361, 0.15532451,\n",
       "        0.00830779, 0.02341566, 0.05723634, 0.1094327 , 0.15603609,\n",
       "        0.01279526, 0.02308359, 0.05898595, 0.10500665, 0.14816604,\n",
       "        0.01022921, 0.02270575, 0.05076303, 0.10010157, 0.1544333 ,\n",
       "        0.01332631, 0.02064099, 0.05137239, 0.09801702, 0.1461472 ,\n",
       "        0.01009979, 0.01645613, 0.04855633, 0.09688749, 0.14702916,\n",
       "        0.01201468, 0.0198451 , 0.05549502, 0.09869876, 0.14940991,\n",
       "        0.01244345, 0.02335067, 0.050419  , 0.10195193, 0.14875264,\n",
       "        0.00966897, 0.02004862, 0.04738336, 0.09976954, 0.15170264,\n",
       "        0.01003542, 0.02014146, 0.04712644, 0.09402514, 0.14551744,\n",
       "        0.00965633, 0.01992831, 0.04919724, 0.09927163, 0.14486313,\n",
       "        0.01328387, 0.02070909, 0.05382633, 0.10173478, 0.14174857,\n",
       "        0.01288657, 0.02092381, 0.05897622, 0.11156092, 0.17180295,\n",
       "        0.01022353, 0.02281032, 0.05688539, 0.11246376, 0.16310706,\n",
       "        0.01078386, 0.0218853 , 0.05404463, 0.10971708, 0.15451303,\n",
       "        0.01250043, 0.02337918, 0.0508944 , 0.10730686, 0.15837126,\n",
       "        0.01398869, 0.02454429, 0.0522212 , 0.11962299, 0.15167518,\n",
       "        0.01114516, 0.02680249, 0.05689392, 0.10412703, 0.16570115,\n",
       "        0.01300473, 0.02510886, 0.05223179, 0.10360179, 0.1569088 ,\n",
       "        0.00625014, 0.02401509, 0.05363889, 0.09999967, 0.15528021,\n",
       "        0.00937505, 0.0187501 , 0.05624995, 0.10008645, 0.15011053,\n",
       "        0.0125    , 0.01562514, 0.04736915, 0.09751582, 0.15376077,\n",
       "        0.01190882, 0.01936178, 0.04809275, 0.1       , 0.14693623,\n",
       "        0.0062501 , 0.02324924, 0.05346465, 0.09919534, 0.14684377,\n",
       "        0.01030188, 0.01981812, 0.05003319, 0.10313253, 0.15029488,\n",
       "        0.01583486, 0.01961222, 0.05167856, 0.10333395, 0.15991225,\n",
       "        0.0131835 , 0.02332644, 0.05299082, 0.09875498, 0.1484313 ,\n",
       "        0.01086516, 0.01980224, 0.04834442, 0.09580922, 0.13843307,\n",
       "        0.01562505, 0.02429523, 0.05496759, 0.11746173, 0.1689611 ,\n",
       "        0.00624995, 0.02187519, 0.05914855, 0.10851011, 0.16895618,\n",
       "        0.0125    , 0.02499743, 0.05428872, 0.10802507, 0.16350746,\n",
       "        0.0062501 , 0.0238956 , 0.05186238, 0.10601082, 0.15841327,\n",
       "        0.01249995, 0.02258902, 0.05146146, 0.09829321, 0.15506086,\n",
       "        0.00801358, 0.02041965, 0.05061998, 0.1055387 , 0.15920238,\n",
       "        0.00625005, 0.02187519, 0.05607514, 0.1048687 , 0.15836306,\n",
       "        0.01353168, 0.02235284, 0.04928122, 0.10273294, 0.15817099,\n",
       "        0.0156249 , 0.0218749 , 0.0549715 , 0.10057569, 0.15321584,\n",
       "        0.00937505, 0.01874976, 0.05312462, 0.10189109, 0.14372687,\n",
       "        0.01258559, 0.01875005, 0.05178776, 0.10035367, 0.15217109,\n",
       "        0.01149106, 0.02188134, 0.04760494, 0.09810495, 0.15006599,\n",
       "        0.01160655, 0.02190166, 0.05079384, 0.09744568, 0.14887519,\n",
       "        0.00824518, 0.02364626, 0.05293832, 0.09940629, 0.14724836,\n",
       "        0.00971842, 0.01939011, 0.0508163 , 0.10224195, 0.14714127,\n",
       "        0.01154585, 0.01976347, 0.0493578 , 0.09888458, 0.14595609,\n",
       "        0.01141162, 0.02467046, 0.05550799, 0.11159525, 0.1716713 ,\n",
       "        0.01182952, 0.01979413, 0.05544786, 0.11344538, 0.16375122,\n",
       "        0.01303892, 0.02391772, 0.0548367 , 0.10923967, 0.164748  ,\n",
       "        0.01160898, 0.02431889, 0.05295577, 0.10835524, 0.15603261,\n",
       "        0.01044827, 0.02308083, 0.05131221, 0.10265884, 0.15616221,\n",
       "        0.01067672, 0.01922631, 0.05339708, 0.10434527, 0.15665483,\n",
       "        0.01181693, 0.02473187, 0.05346336, 0.10502782, 0.15755124,\n",
       "        0.00949492, 0.02121196, 0.05150785, 0.10308909, 0.15831409,\n",
       "        0.00988827, 0.02375875, 0.05122089, 0.10014596, 0.15033479,\n",
       "        0.01359162, 0.02213593, 0.0464129 , 0.09902472, 0.14742699,\n",
       "        0.00942492, 0.02240825, 0.05066781, 0.09733958, 0.15295057,\n",
       "        0.01250005, 0.02253366, 0.05166306, 0.10063524, 0.15356865,\n",
       "        0.01446986, 0.01839986, 0.04569845, 0.09093537, 0.14489245,\n",
       "        0.01018543, 0.01883106, 0.04633446, 0.0953208 , 0.14046664,\n",
       "        0.01164289, 0.02004857, 0.04667754, 0.09974599, 0.14115171,\n",
       "        0.00652399, 0.01562486, 0.05321279, 0.09625263, 0.14516463,\n",
       "        0.01250005, 0.02499995, 0.06069703, 0.12180438, 0.18257709,\n",
       "        0.01698709, 0.0251864 , 0.06269426, 0.12322726, 0.17213755,\n",
       "        0.01336155, 0.02022719, 0.05908961, 0.111485  , 0.17026262,\n",
       "        0.01374526, 0.02516518, 0.05590816, 0.11232276, 0.16472793,\n",
       "        0.00937495, 0.02348814, 0.05208063, 0.1083354 , 0.16348987,\n",
       "        0.00999942, 0.01854749, 0.05407791, 0.11005173, 0.15357232,\n",
       "        0.01562614, 0.0224853 , 0.0569767 , 0.10708313, 0.15996246,\n",
       "        0.01315942, 0.02404847, 0.05561705, 0.10937071, 0.15135593,\n",
       "        0.01242728, 0.02096562, 0.05405717, 0.10444484, 0.15348077,\n",
       "        0.01287322, 0.02411122, 0.051756  , 0.10197182, 0.15246449,\n",
       "        0.01548281, 0.01935387, 0.04870481, 0.10452271, 0.15843449,\n",
       "        0.01491013, 0.01771555, 0.05321126, 0.10392513, 0.15827885,\n",
       "        0.00966377, 0.01644163, 0.05101409, 0.0995101 , 0.15142617,\n",
       "        0.01165676, 0.02544584, 0.05009894, 0.10120292, 0.14423776,\n",
       "        0.01258421, 0.02373128, 0.05112343, 0.10319228, 0.14372506,\n",
       "        0.01249995, 0.02187505, 0.0524343 , 0.09925036, 0.14056387,\n",
       "        0.01595545, 0.02424984, 0.06351638, 0.12500081, 0.18437705,\n",
       "        0.01490588, 0.0249999 , 0.05991683, 0.11822042, 0.18961244,\n",
       "        0.01670198, 0.02732368, 0.06262531, 0.11812406, 0.17749977,\n",
       "        0.01730404, 0.02349787, 0.05879941, 0.11308141, 0.17030711,\n",
       "        0.01562476, 0.02197452, 0.05932784, 0.10949154, 0.16854091,\n",
       "        0.01335216, 0.02222586, 0.05841522, 0.10416608, 0.16311512,\n",
       "        0.01405673, 0.02627697, 0.0580554 , 0.11093335, 0.16358895,\n",
       "        0.0123992 , 0.02504969, 0.05728664, 0.10880899, 0.16061034,\n",
       "        0.01048636, 0.02380428, 0.05420136, 0.10082111, 0.15634246,\n",
       "        0.01563101, 0.02345653, 0.05785093, 0.10610838, 0.15491061,\n",
       "        0.01562495, 0.02187505, 0.05297513, 0.11752572, 0.15643716,\n",
       "        0.00994825, 0.02783337, 0.05248861, 0.10997853, 0.15699749,\n",
       "        0.01261177, 0.02271976, 0.04989085, 0.10552573, 0.15457754,\n",
       "        0.00805926, 0.02562823, 0.04892058, 0.10171466, 0.15375872,\n",
       "        0.01310649, 0.02022686, 0.05399899, 0.10106702, 0.15135455,\n",
       "        0.00900841, 0.02135515, 0.05206218, 0.10182586, 0.15340123,\n",
       "        0.00770998, 0.02835822, 0.06267529, 0.12661014, 0.1854969 ,\n",
       "        0.01214023, 0.02640204, 0.06080556, 0.12160225, 0.18525815,\n",
       "        0.01384349, 0.02365499, 0.06069498, 0.1184206 , 0.17292514,\n",
       "        0.0136889 , 0.0218225 , 0.05721731, 0.11839304, 0.17065468,\n",
       "        0.01377521, 0.02294111, 0.05542927, 0.11416006, 0.17031898,\n",
       "        0.01324329, 0.02316098, 0.05828228, 0.1143486 , 0.1705193 ,\n",
       "        0.00911999, 0.0233377 , 0.05890489, 0.11558604, 0.16804724,\n",
       "        0.01593509, 0.02218456, 0.05635548, 0.1092988 , 0.16347971,\n",
       "        0.00798879, 0.02672701, 0.05327249, 0.10354724, 0.15781717,\n",
       "        0.01021008, 0.02654433, 0.05169845, 0.1037919 , 0.15687332,\n",
       "        0.016364  , 0.01665764, 0.0561933 , 0.10572481, 0.15231638,\n",
       "        0.01208544, 0.0167006 , 0.05319991, 0.10081735, 0.15273552,\n",
       "        0.01324935, 0.02109866, 0.04992719, 0.10030246, 0.14841137,\n",
       "        0.0103395 , 0.01759562, 0.05328326, 0.10027781, 0.14916258,\n",
       "        0.01022029, 0.02014995, 0.05012593, 0.10328574, 0.15300398,\n",
       "        0.01336193, 0.02346091, 0.05190969, 0.10460143, 0.1490314 ,\n",
       "        0.00926356, 0.02624764, 0.06608067, 0.12581739, 0.17708154,\n",
       "        0.01562514, 0.02500005, 0.0625    , 0.12302608, 0.18109026,\n",
       "        0.01562543, 0.02499967, 0.05937486, 0.12055111, 0.20022612,\n",
       "        0.01874919, 0.02499967, 0.06339879, 0.11667976, 0.17196841,\n",
       "        0.        , 0.02500067, 0.05514188, 0.11457424, 0.16571183,\n",
       "        0.01241846, 0.02669482, 0.05680432, 0.11021829, 0.16817079,\n",
       "        0.01327162, 0.02330484, 0.05619016, 0.10699029, 0.16594181,\n",
       "        0.01329455, 0.01710629, 0.05035896, 0.10636001, 0.15875754,\n",
       "        0.01356678, 0.01654882, 0.05321765, 0.10015593, 0.1501359 ,\n",
       "        0.01194367, 0.02329807, 0.05221386, 0.10016875, 0.15965738,\n",
       "        0.01133161, 0.02663817, 0.05143723, 0.1038837 , 0.15345001,\n",
       "        0.01008554, 0.02000442, 0.05353451, 0.10572577, 0.15851955,\n",
       "        0.01291971, 0.02293086, 0.05244932, 0.10321684, 0.15012217,\n",
       "        0.0122201 , 0.0201354 , 0.0497262 , 0.10067406, 0.1515131 ,\n",
       "        0.0104507 , 0.02285495, 0.04985337, 0.10004849, 0.14369097,\n",
       "        0.01307406, 0.02058282, 0.05331011, 0.10323205, 0.15009913]),\n",
       " 'std_fit_time': array([6.18734820e-03, 7.90872512e-03, 6.63406295e-03, 6.51077851e-03,\n",
       "        6.27094613e-03, 6.38825569e-03, 8.57935559e-03, 6.52470535e-03,\n",
       "        9.72989506e-04, 7.06844737e-03, 7.66617471e-03, 3.57060250e-03,\n",
       "        5.94270869e-03, 7.43310921e-03, 8.89945446e-03, 3.47006842e-03,\n",
       "        6.13827863e-03, 5.50296719e-03, 4.77541255e-03, 8.97557857e-03,\n",
       "        9.25143751e-03, 6.88665579e-03, 5.01186487e-03, 6.69633788e-03,\n",
       "        5.44268985e-03, 6.52495485e-03, 6.98768976e-03, 4.34503857e-03,\n",
       "        1.39093577e-02, 6.97066325e-03, 6.58103654e-03, 7.64972572e-03,\n",
       "        6.69436411e-03, 4.86948921e-03, 4.33838414e-03, 7.93276960e-03,\n",
       "        6.76610241e-03, 8.91354294e-03, 1.17836737e-04, 8.54478777e-03,\n",
       "        6.81050545e-03, 5.92187822e-03, 4.04953067e-03, 6.10453498e-03,\n",
       "        5.80131130e-03, 6.57677365e-03, 2.01395935e-03, 4.90333580e-03,\n",
       "        4.72963040e-03, 6.86785982e-03, 6.20367870e-03, 6.75301507e-03,\n",
       "        6.91371352e-03, 6.31845090e-03, 3.82596676e-03, 6.75835474e-03,\n",
       "        9.13137956e-03, 4.54861626e-04, 4.29526670e-03, 6.93228847e-03,\n",
       "        7.62319518e-03, 6.67152891e-03, 5.39823305e-03, 1.15714222e-03,\n",
       "        3.24436482e-03, 8.19404863e-03, 6.87981895e-03, 5.65848046e-03,\n",
       "        7.63082167e-03, 6.40796511e-03, 7.33563600e-03, 6.70031048e-04,\n",
       "        1.48129461e-03, 1.63371406e-03, 6.74905376e-03, 5.51206745e-03,\n",
       "        5.72968124e-03, 7.24949081e-03, 7.13257450e-03, 8.63469880e-03,\n",
       "        5.49977067e-03, 5.76329133e-03, 7.90180609e-03, 5.95035112e-03,\n",
       "        8.58383370e-03, 8.01183727e-03, 8.21796768e-03, 6.90588596e-03,\n",
       "        5.51652423e-03, 5.61116131e-03, 6.34613656e-03, 7.64685390e-03,\n",
       "        4.98648472e-03, 8.05811014e-03, 7.54895755e-03, 6.25021468e-03,\n",
       "        7.12027555e-03, 3.30679877e-03, 6.42408036e-03, 6.09234373e-03,\n",
       "        3.29867710e-03, 7.92332066e-03, 5.96643034e-03, 8.77796007e-03,\n",
       "        5.44628988e-03, 7.08440542e-03, 4.27553960e-03, 1.54601834e-03,\n",
       "        7.36695892e-03, 1.59089473e-03, 5.96160813e-03, 5.48525918e-03,\n",
       "        6.47149945e-03, 8.38798899e-03, 3.31741114e-03, 7.65483066e-03,\n",
       "        9.22580019e-03, 6.91099715e-03, 7.65612241e-03, 2.16447818e-03,\n",
       "        7.65469438e-03, 6.24971392e-03, 7.65481119e-03, 7.58552008e-03,\n",
       "        7.76068751e-03, 6.25000000e-03, 7.92181383e-07, 9.89485505e-04,\n",
       "        6.05505169e-03, 2.51305507e-03, 1.46386587e-03, 8.12867760e-03,\n",
       "        7.08824046e-03, 7.65523953e-03, 7.72072513e-03, 7.65477225e-03,\n",
       "        5.90536749e-03, 4.59670360e-03, 1.88069954e-03, 2.93639612e-03,\n",
       "        7.57157585e-03, 6.78746228e-03, 5.57560504e-04, 1.52556334e-02,\n",
       "        5.48652295e-04, 5.31771437e-03, 8.43649242e-03, 2.74500290e-03,\n",
       "        6.46188667e-03, 9.09304392e-03, 7.06083716e-03, 7.65993805e-03,\n",
       "        6.36639251e-03, 3.29451041e-03, 1.04397367e-02, 9.27917831e-03,\n",
       "        7.52362051e-03, 7.90495833e-03, 6.71995534e-03, 3.86251999e-03,\n",
       "        5.51978917e-07, 7.67949939e-03, 5.61191510e-03, 6.68553005e-03,\n",
       "        6.07969269e-03, 7.65459706e-03, 7.65479177e-03, 7.76042078e-03,\n",
       "        2.42701343e-03, 6.12072189e-03, 6.25000001e-03, 5.68212537e-03,\n",
       "        1.37065234e-03, 8.00453504e-03, 5.61464773e-03, 7.65477225e-03,\n",
       "        7.04734592e-03, 9.07446529e-03, 5.24004696e-03, 3.99752682e-03,\n",
       "        6.24997618e-03, 4.72447911e-03, 1.67451254e-03, 7.78766782e-03,\n",
       "        3.63024041e-03, 6.66019415e-03, 7.80568883e-03, 6.05985628e-03,\n",
       "        7.18323927e-03, 6.20002260e-03, 7.65471385e-03, 7.65459705e-03,\n",
       "        7.58137735e-03, 6.25797167e-03, 2.63750763e-03, 6.86507748e-03,\n",
       "        1.78197856e-03, 8.79650708e-03, 9.28717523e-03, 7.23212994e-03,\n",
       "        4.67203091e-07, 7.65541483e-03, 7.01018536e-03, 7.02353681e-03,\n",
       "        6.29764614e-03, 7.65469439e-03, 6.25035767e-03, 7.65525892e-03,\n",
       "        7.62916615e-03, 6.25529554e-03, 6.29706441e-03, 6.24949934e-03,\n",
       "        6.37216419e-03, 4.12006163e-04, 1.05857684e-02, 8.29558057e-03,\n",
       "        7.64929105e-03, 7.12485986e-03, 4.15847361e-03, 4.69922307e-03,\n",
       "        3.31354005e-03, 3.60831576e-03, 2.56406680e-03, 4.03859841e-03,\n",
       "        6.44707075e-03, 6.59088077e-03, 8.38644156e-03, 3.41342243e-03,\n",
       "        5.88772361e-03, 2.21533278e-03, 3.89844915e-03, 7.93362871e-03,\n",
       "        4.47543363e-03, 5.81350909e-03, 3.88281107e-03, 5.79247533e-03,\n",
       "        7.51101096e-03, 2.76759836e-03, 3.25406673e-03, 6.36362986e-03,\n",
       "        7.65895914e-03, 4.05981473e-03, 2.80121698e-03, 2.12448454e-03,\n",
       "        7.66142650e-03, 6.86131614e-03, 5.10434566e-03, 6.37078961e-03,\n",
       "        4.80056216e-03, 6.34819717e-03, 5.37070720e-03, 5.71603874e-03,\n",
       "        2.41800196e-03, 7.73452093e-03, 4.48468814e-03, 4.10473369e-04,\n",
       "        8.89939264e-03, 4.50491209e-03, 5.52787087e-03, 6.93939945e-04,\n",
       "        9.19137917e-03, 7.02405376e-03, 6.14360671e-03, 6.79704144e-03,\n",
       "        3.67575148e-03, 7.04468567e-03, 6.31084389e-03, 5.26148140e-03,\n",
       "        3.66246075e-03, 3.42658909e-03, 6.13029280e-03, 5.26717465e-03,\n",
       "        3.07189211e-03, 6.08616502e-03, 4.98956915e-03, 4.83808446e-03,\n",
       "        1.07094483e-02, 8.79148816e-03, 7.92633403e-03, 3.41996472e-03,\n",
       "        4.77743672e-03, 4.17762316e-03, 8.05728496e-03, 9.90967700e-04,\n",
       "        7.70249104e-03, 8.75089081e-03, 8.97165729e-04, 5.36698742e-03,\n",
       "        4.93315770e-03, 6.24672910e-03, 7.48235397e-03, 5.99965879e-03,\n",
       "        6.33848918e-04, 2.76419996e-03, 6.20215883e-03, 6.25002384e-03,\n",
       "        7.18550453e-03, 5.52070933e-03, 6.67005147e-03, 5.10840966e-03,\n",
       "        9.32252783e-03, 5.20836921e-03, 9.24108102e-03, 9.87959269e-03,\n",
       "        5.83652825e-03, 9.34908404e-03, 6.21120680e-03, 2.76332550e-03,\n",
       "        2.32764503e-03, 7.46234475e-03, 1.14654538e-03, 8.88939347e-04,\n",
       "        5.77293345e-03, 6.44826358e-03, 9.94163506e-03, 5.35535288e-03,\n",
       "        3.56832255e-07, 6.00833279e-03, 1.00561667e-02, 8.46842121e-03,\n",
       "        6.25002384e-03, 7.65432452e-03, 7.71894034e-03, 8.45752443e-03,\n",
       "        8.49110308e-03, 1.02867792e-03, 7.37455110e-03, 4.97387861e-03,\n",
       "        5.40188299e-03, 3.76247883e-03, 2.78665954e-03, 7.07742554e-03,\n",
       "        1.59508503e-03, 8.03281614e-03, 4.24600144e-03, 5.02947641e-03,\n",
       "        5.16563704e-03, 8.95318919e-03, 2.34598851e-03, 3.68191962e-03,\n",
       "        7.65461652e-03, 6.95354816e-03, 5.33919786e-03, 4.50511176e-03,\n",
       "        5.80853178e-03, 5.41369082e-03, 4.88042605e-03, 6.49567861e-03,\n",
       "        5.95109079e-03, 2.55875373e-03, 2.54739960e-06, 6.71131132e-03,\n",
       "        9.06553593e-03, 5.09452963e-03, 3.50860733e-03, 2.71930972e-03,\n",
       "        3.48675468e-03, 5.60199490e-03, 5.87417354e-03, 5.96865551e-03,\n",
       "        6.66833024e-03, 1.59432248e-03, 2.28039027e-03, 6.74542822e-03,\n",
       "        7.26620870e-03, 5.35543020e-03, 5.62234951e-03, 9.83844459e-03,\n",
       "        5.60807018e-03, 6.13754417e-03, 7.15914900e-03, 5.79429634e-03,\n",
       "        7.58499657e-03, 7.43415839e-03, 7.71834813e-03, 1.72241748e-03,\n",
       "        7.32240866e-03, 7.76169748e-03, 8.49341899e-03, 7.40230816e-03,\n",
       "        6.90458305e-03, 1.63326264e-03, 1.78850209e-03, 3.65925593e-03,\n",
       "        6.35572596e-03, 1.04057954e-02, 4.46198769e-03, 5.21423164e-03,\n",
       "        6.66116826e-03, 6.74174002e-03, 3.93855759e-03, 8.10661256e-03,\n",
       "        8.49590303e-03, 9.31705569e-03, 4.51357551e-03, 6.24997616e-03,\n",
       "        7.65461652e-03, 8.21587397e-03, 5.93180875e-03, 4.01271051e-04,\n",
       "        6.61015586e-04, 7.05644263e-03, 1.60618825e-03, 4.18460098e-03,\n",
       "        1.00518524e-02, 1.45234199e-03, 7.65486959e-03, 6.64884432e-03,\n",
       "        1.17770677e-03, 4.86505145e-03, 5.88976839e-03, 5.29176904e-03,\n",
       "        6.00225169e-03, 7.24220267e-03, 6.28727898e-03, 7.74602420e-03,\n",
       "        8.47664868e-03, 9.16832755e-03, 4.59660861e-03, 1.04261710e-02,\n",
       "        7.23159356e-07, 7.77546390e-03, 6.27944820e-03, 2.33675138e-04,\n",
       "        5.98314913e-03, 1.30676159e-03, 9.38841525e-03, 6.75269607e-03,\n",
       "        4.53169150e-03, 8.49497926e-03, 8.44650346e-03, 4.02671374e-03,\n",
       "        3.90350719e-03, 4.09855394e-03, 6.06552699e-03, 4.89611134e-03,\n",
       "        3.07254745e-03, 7.35624931e-03, 8.88464178e-03, 7.89435043e-03,\n",
       "        6.49007407e-03, 8.19936591e-03, 8.89571425e-03, 7.14311920e-03,\n",
       "        1.84918680e-04, 1.08383733e-05, 6.99495540e-03, 7.40018610e-03,\n",
       "        6.68469210e-03, 4.45387226e-03, 1.44159474e-06, 7.65374058e-03,\n",
       "        6.62560340e-03, 8.98128116e-03, 4.35596098e-03, 6.74734841e-03,\n",
       "        6.15233007e-03, 4.09236610e-03, 4.80767403e-03, 5.91359404e-03,\n",
       "        6.91280796e-03, 7.39080154e-03, 1.27998183e-03, 2.91651697e-03,\n",
       "        6.40594019e-03, 6.38213125e-03, 8.49129010e-03, 5.11846978e-03,\n",
       "        5.30577274e-03, 9.62750264e-03, 6.53617709e-03, 4.08744344e-03,\n",
       "        8.17425253e-03, 2.69162985e-03, 1.77571106e-03, 4.32598172e-03,\n",
       "        5.48619164e-03, 2.15788284e-03, 6.74919857e-03, 4.78473090e-03,\n",
       "        4.65642632e-03, 7.84204831e-03, 1.29735325e-04, 8.81121943e-03,\n",
       "        4.94725673e-03, 5.04008991e-03, 6.97065790e-03, 7.82087510e-03,\n",
       "        3.09159953e-03, 9.31115825e-03, 6.89426912e-04, 7.94297036e-03,\n",
       "        2.26814420e-03, 2.05006390e-03, 4.14591654e-03, 7.99980263e-03,\n",
       "        7.51152209e-03, 6.32104161e-03, 5.33955736e-03, 4.30921736e-03,\n",
       "        5.22502699e-03, 2.99459771e-03, 6.25049037e-03, 4.41799841e-03,\n",
       "        5.27827009e-03, 6.63172101e-03, 8.02807645e-03, 1.03104048e-02,\n",
       "        3.08499735e-03, 6.73972242e-03, 1.08965376e-02, 1.03775165e-02,\n",
       "        6.80600191e-03, 4.37565472e-03, 7.51609378e-03, 6.55972734e-03,\n",
       "        3.34037942e-03, 7.60296038e-03, 8.28861932e-03, 6.68892215e-03,\n",
       "        5.91916909e-03, 8.39149621e-03, 6.40996693e-03, 6.44847343e-03,\n",
       "        6.61901723e-03, 7.68720365e-03, 7.91727803e-03, 4.50562331e-03,\n",
       "        6.71175276e-03, 7.45690245e-03, 9.59161287e-04, 7.19999477e-05,\n",
       "        7.60211684e-03, 7.60113422e-03, 8.91372017e-03, 5.58533197e-03,\n",
       "        2.15853053e-04, 6.15480411e-03, 7.08231747e-03, 5.36099713e-03,\n",
       "        6.67594770e-03, 6.67935541e-03, 6.07932827e-04, 6.52705843e-04,\n",
       "        3.98491834e-03, 8.44660773e-03, 1.07274979e-03, 6.07267605e-03,\n",
       "        5.46926808e-04, 5.47150089e-03, 8.35572747e-03, 6.61818163e-03,\n",
       "        1.94757224e-04, 6.69882847e-03, 5.56010364e-03, 6.69048837e-03,\n",
       "        8.15840088e-03, 2.90712195e-03, 5.89169048e-03, 6.05156176e-03,\n",
       "        7.62887623e-03, 8.42585519e-03, 3.80139560e-03, 5.48354379e-03,\n",
       "        6.74063402e-03, 5.76164530e-07, 7.65488905e-03, 5.00111031e-07,\n",
       "        3.61643468e-03, 6.04703181e-03, 4.10190833e-07, 7.65467496e-03,\n",
       "        6.25016690e-03, 9.62053289e-03, 1.55695951e-02, 6.25028623e-03,\n",
       "        7.65516238e-03, 1.79877295e-03, 7.54628231e-03, 1.86590188e-04,\n",
       "        0.00000000e+00, 7.65490943e-03, 7.04718449e-03, 7.64934195e-03,\n",
       "        7.54811222e-03, 6.26123124e-03, 7.22382553e-03, 8.09991647e-03,\n",
       "        8.24108016e-03, 2.65623153e-03, 6.74720264e-03, 6.95504891e-03,\n",
       "        8.55604908e-03, 8.84073859e-03, 1.06391166e-03, 6.64790455e-03,\n",
       "        9.67181245e-04, 9.81844662e-04, 7.65400480e-03, 6.87028562e-03,\n",
       "        6.35305541e-03, 3.00331121e-04, 6.75248953e-03, 1.53628955e-04,\n",
       "        2.15393146e-03, 1.26569559e-04, 8.46083962e-03, 4.97153775e-03,\n",
       "        5.15645016e-03, 8.68410098e-03, 6.59995543e-03, 9.11474283e-03,\n",
       "        7.91462092e-03, 6.56832583e-03, 6.71111281e-03, 7.29630389e-03,\n",
       "        6.50620678e-03, 7.12536892e-03, 7.16264605e-03, 7.95667487e-03,\n",
       "        6.26456537e-03, 8.47094181e-03, 5.65203127e-03, 6.17557375e-03,\n",
       "        1.08216194e-04, 6.63257317e-03, 8.27028139e-03, 1.70431080e-03,\n",
       "        9.11973107e-04, 4.57127050e-03, 8.57158406e-03, 8.50746865e-03,\n",
       "        8.29867496e-04, 1.44638427e-04, 7.95015078e-03, 5.96006210e-03,\n",
       "        3.61538575e-03, 6.51964899e-03, 6.25486644e-03, 1.15521377e-04]),\n",
       " 'mean_score_time': array([5.69248199e-04, 4.00066376e-04, 1.79986954e-03, 7.76386261e-03,\n",
       "        1.08377934e-02, 2.33840942e-04, 1.05414391e-03, 3.25655937e-03,\n",
       "        6.25681877e-03, 1.17212772e-02, 3.12509537e-03, 3.17692757e-03,\n",
       "        3.33414078e-03, 7.32946396e-04, 3.12504768e-03, 0.00000000e+00,\n",
       "        1.01990700e-03, 9.54847336e-03, 0.00000000e+00, 6.55717850e-03,\n",
       "        3.13487053e-03, 3.10091972e-03, 3.12504768e-03, 7.36012459e-03,\n",
       "        1.31560326e-02, 3.59239578e-03, 3.12495232e-03, 0.00000000e+00,\n",
       "        8.07528496e-03, 1.01474762e-02, 3.59787941e-03, 5.99718094e-04,\n",
       "        9.98926163e-04, 4.47168350e-03, 8.63471031e-03, 3.12528610e-03,\n",
       "        3.27081680e-03, 3.33127975e-03, 6.61320686e-03, 5.77111244e-03,\n",
       "        0.00000000e+00, 2.16770172e-04, 4.12182808e-03, 6.64644241e-03,\n",
       "        6.90860748e-03, 3.69844437e-03, 3.32403183e-03, 4.63824272e-03,\n",
       "        9.58328247e-03, 6.86430931e-03, 7.99751282e-04, 3.53178978e-03,\n",
       "        1.10535622e-03, 7.09729195e-03, 4.31613922e-03, 4.69255447e-04,\n",
       "        3.12514305e-03, 3.18193436e-03, 1.43260956e-03, 8.42027664e-03,\n",
       "        3.30686569e-03, 3.12519073e-03, 3.00383568e-03, 0.00000000e+00,\n",
       "        1.74379349e-03, 3.23562622e-03, 3.35321426e-03, 6.22959137e-03,\n",
       "        9.35559273e-03, 4.97331619e-03, 3.35116386e-03, 3.83052826e-03,\n",
       "        4.26383018e-03, 0.00000000e+00, 5.10010719e-03, 1.17673874e-03,\n",
       "        0.00000000e+00, 4.20570374e-04, 3.84163857e-03, 9.38482285e-03,\n",
       "        6.68096542e-04, 6.24976158e-03, 3.40800285e-03, 5.57837486e-03,\n",
       "        8.35576057e-03, 0.00000000e+00, 3.71952057e-03, 3.16238403e-03,\n",
       "        4.32062149e-03, 9.58724022e-03, 3.12500000e-03, 1.03778839e-03,\n",
       "        3.12504768e-03, 3.12500000e-03, 1.32317543e-02, 0.00000000e+00,\n",
       "        3.12514305e-03, 6.24971390e-03, 4.74243164e-03, 6.22820854e-03,\n",
       "        0.00000000e+00, 2.01544762e-03, 1.32355690e-03, 7.21392632e-03,\n",
       "        1.53253555e-02, 3.10673714e-03, 2.72383690e-03, 3.63612175e-03,\n",
       "        3.68690491e-03, 7.65848160e-04, 3.55577469e-04, 8.00037384e-04,\n",
       "        3.72490883e-03, 7.50479698e-03, 6.24995232e-03, 6.25004768e-03,\n",
       "        5.99575043e-04, 3.18655968e-03, 1.35325432e-02, 6.25014305e-03,\n",
       "        3.12490463e-03, 0.00000000e+00, 0.00000000e+00, 3.12490463e-03,\n",
       "        6.24990463e-03, 0.00000000e+00, 6.24990463e-03, 3.13224792e-03,\n",
       "        6.25023842e-03, 5.87458611e-03, 1.68080330e-03, 4.17284966e-03,\n",
       "        4.36701775e-03, 9.37509537e-03, 1.05751514e-02, 3.12500000e-03,\n",
       "        9.99689102e-04, 1.64647102e-03, 6.67943954e-03, 9.92383957e-03,\n",
       "        2.91018486e-03, 3.33428383e-03, 3.37495804e-03, 1.00101471e-02,\n",
       "        3.30224037e-03, 8.19826126e-04, 3.53975296e-03, 1.35469437e-03,\n",
       "        3.45244408e-03, 6.82373047e-03, 3.45659256e-04, 0.00000000e+00,\n",
       "        3.00884247e-04, 7.98082352e-03, 4.99997139e-03, 3.52511406e-03,\n",
       "        2.52342224e-03, 3.72509956e-03, 8.42566490e-03, 1.09848022e-02,\n",
       "        0.00000000e+00, 3.47533226e-03, 1.43966675e-03, 4.12487984e-03,\n",
       "        9.35115814e-03, 3.12500000e-03, 6.24980927e-03, 1.34196281e-03,\n",
       "        5.99694252e-03, 6.25004768e-03, 0.00000000e+00, 2.26736069e-03,\n",
       "        2.93598175e-03, 4.25691605e-03, 6.45227432e-03, 3.12504768e-03,\n",
       "        3.52487564e-03, 3.12495232e-03, 6.16240501e-03, 6.20594025e-03,\n",
       "        0.00000000e+00, 1.60045624e-03, 5.00607491e-03, 1.47960186e-02,\n",
       "        8.30321312e-03, 6.88257217e-03, 1.20000839e-03, 6.24985695e-03,\n",
       "        5.34629822e-03, 3.66716385e-03, 3.12509537e-03, 3.12490463e-03,\n",
       "        3.52630615e-03, 4.91895676e-03, 6.89449310e-03, 4.00018692e-04,\n",
       "        1.85699463e-03, 6.22596741e-03, 5.28364182e-03, 3.90491486e-03,\n",
       "        0.00000000e+00, 3.12495232e-03, 7.16114044e-04, 3.12500000e-03,\n",
       "        3.12514305e-03, 3.12480927e-03, 6.25038147e-03, 0.00000000e+00,\n",
       "        4.36067581e-03, 9.37514305e-03, 3.12595367e-03, 3.12509537e-03,\n",
       "        6.45685196e-03, 2.47478485e-05, 1.18206978e-02, 1.11703873e-03,\n",
       "        3.12495232e-03, 6.84990883e-03, 6.25615120e-03, 6.67967796e-03,\n",
       "        1.31359100e-03, 9.33742523e-04, 3.96628380e-03, 4.91914749e-03,\n",
       "        6.13832474e-03, 2.92196274e-03, 2.77204514e-03, 2.62241364e-03,\n",
       "        2.57172585e-03, 6.93740845e-03, 3.53679657e-03, 2.01687813e-03,\n",
       "        1.08814240e-03, 3.23581696e-03, 6.63189888e-03, 1.20100975e-03,\n",
       "        2.07829475e-03, 3.72514725e-03, 4.88395691e-03, 7.23280907e-03,\n",
       "        3.78303528e-03, 1.80025101e-03, 5.68485260e-03, 8.02922249e-03,\n",
       "        4.98204231e-03, 3.65829468e-03, 1.39980316e-03, 5.55310249e-03,\n",
       "        3.06706429e-03, 1.17600441e-02, 1.46737099e-03, 1.56269073e-03,\n",
       "        1.67183876e-03, 6.94708824e-03, 6.27837181e-03, 2.22210884e-03,\n",
       "        1.05848312e-03, 4.63409424e-03, 2.10151672e-03, 9.37485695e-03,\n",
       "        3.92518044e-03, 0.00000000e+00, 6.87894821e-03, 7.48810768e-03,\n",
       "        7.91616440e-03, 3.48339081e-03, 5.43999672e-03, 4.24351692e-03,\n",
       "        8.39171410e-03, 6.08739853e-03, 1.32031441e-03, 1.94644928e-03,\n",
       "        2.74853706e-03, 2.42209435e-03, 5.38458824e-03, 4.78706360e-03,\n",
       "        4.03194427e-03, 1.66554451e-03, 6.96716309e-03, 7.03830719e-03,\n",
       "        1.19953156e-03, 2.15792656e-03, 3.19061279e-03, 2.75335312e-03,\n",
       "        6.10408783e-03, 1.56035423e-03, 1.84268951e-03, 7.24854469e-03,\n",
       "        7.88059235e-03, 8.43987465e-03, 3.74984741e-03, 1.49989128e-03,\n",
       "        3.31978798e-03, 8.56356621e-03, 6.41407967e-03, 0.00000000e+00,\n",
       "        2.15339661e-03, 1.46951675e-03, 3.71193886e-03, 1.98864937e-03,\n",
       "        1.03268623e-03, 4.93659973e-03, 4.06041145e-03, 1.10283375e-02,\n",
       "        6.82024956e-03, 3.86095047e-03, 0.00000000e+00, 6.84990883e-03,\n",
       "        6.49094582e-03, 1.25614643e-02, 1.64318085e-03, 2.48870850e-03,\n",
       "        4.72497940e-03, 3.39856148e-03, 1.07748032e-02, 7.04264641e-03,\n",
       "        6.25000000e-03, 0.00000000e+00, 4.35028076e-03, 4.32572365e-03,\n",
       "        0.00000000e+00, 3.12495232e-03, 4.92916107e-03, 1.57155991e-03,\n",
       "        6.73451424e-03, 0.00000000e+00, 1.09720230e-03, 8.00132751e-04,\n",
       "        3.43494415e-03, 9.60412025e-03, 1.23405457e-03, 6.58807755e-03,\n",
       "        3.13477516e-03, 7.25088120e-03, 8.15868378e-03, 7.99846649e-04,\n",
       "        9.31406021e-04, 3.72500420e-03, 5.71212769e-03, 1.10790253e-02,\n",
       "        3.12500000e-03, 4.37021255e-03, 5.00555038e-03, 2.00462341e-03,\n",
       "        8.50224495e-03, 3.74412537e-03, 3.95150185e-03, 4.25701141e-03,\n",
       "        4.18410301e-03, 1.27780914e-02, 0.00000000e+00, 3.81283760e-03,\n",
       "        1.39985085e-03, 8.96468163e-03, 7.80372620e-03, 1.19514465e-03,\n",
       "        1.91106796e-03, 1.92885399e-03, 4.07600403e-03, 9.92293358e-03,\n",
       "        7.99894333e-04, 1.90343857e-03, 3.05385590e-03, 4.62718010e-03,\n",
       "        5.90353012e-03, 9.99546051e-04, 8.00132751e-04, 3.75738144e-03,\n",
       "        5.42416573e-03, 6.11610413e-03, 1.19986534e-03, 3.83906364e-03,\n",
       "        7.25102425e-03, 2.89578438e-03, 2.91452408e-03, 8.00085068e-04,\n",
       "        6.25014305e-03, 0.00000000e+00, 6.24980927e-03, 6.07943535e-03,\n",
       "        3.73167992e-03, 7.42516518e-03, 2.16727257e-03, 4.07862663e-03,\n",
       "        7.40990639e-03, 4.18939590e-03, 2.28505135e-03, 5.37090302e-03,\n",
       "        5.03349304e-03, 1.25000000e-02, 0.00000000e+00, 3.99637222e-04,\n",
       "        4.28671837e-03, 5.59630394e-03, 1.09256744e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.92498970e-03, 4.12721634e-03, 1.56258583e-02,\n",
       "        0.00000000e+00, 3.64427567e-03, 1.12171173e-03, 1.00007057e-03,\n",
       "        7.25002289e-03, 0.00000000e+00, 0.00000000e+00, 7.64942169e-03,\n",
       "        5.27920723e-03, 4.56552505e-03, 1.19986534e-03, 1.23257637e-03,\n",
       "        6.50739670e-04, 6.44741058e-03, 4.61063385e-03, 1.20034218e-03,\n",
       "        1.29098892e-03, 4.55498695e-03, 8.65907669e-03, 7.04245567e-03,\n",
       "        0.00000000e+00, 3.12509537e-03, 0.00000000e+00, 9.37519073e-03,\n",
       "        8.41135979e-03, 1.81345940e-03, 4.39982414e-03, 1.70464516e-03,\n",
       "        1.28362179e-02, 9.09070969e-03, 1.20019913e-03, 9.99975204e-04,\n",
       "        1.73506737e-03, 8.24918747e-03, 1.13170147e-02, 2.00033188e-04,\n",
       "        2.37646103e-03, 9.69839096e-04, 8.48298073e-03, 1.22695923e-02,\n",
       "        6.72531128e-04, 3.00135612e-03, 4.04319763e-03, 9.37514305e-03,\n",
       "        3.12500000e-03, 0.00000000e+00, 0.00000000e+00, 1.40056610e-03,\n",
       "        6.35814667e-03, 7.81397820e-03, 0.00000000e+00, 3.12504768e-03,\n",
       "        2.36439705e-03, 2.23593712e-03, 1.30203247e-02, 3.14507484e-03,\n",
       "        1.60050392e-03, 4.54425812e-03, 4.08921242e-03, 8.54139328e-03,\n",
       "        1.25765800e-03, 1.19905472e-03, 4.81934547e-03, 4.34226990e-03,\n",
       "        6.40935898e-03, 3.72505188e-03, 9.89723206e-04, 7.43513107e-03,\n",
       "        5.06715775e-03, 6.14199638e-03, 1.15671158e-03, 2.05473900e-03,\n",
       "        4.57315445e-03, 4.98838425e-03, 5.71742058e-03, 1.00135803e-03,\n",
       "        3.42860222e-03, 2.42753029e-03, 6.06455803e-03, 5.97257614e-03,\n",
       "        6.03723526e-03, 1.59745216e-03, 3.90558243e-03, 3.56369019e-03,\n",
       "        9.43508148e-03, 2.34942436e-03, 3.78642082e-03, 3.48925591e-03,\n",
       "        4.98394966e-03, 4.47845459e-03, 1.61757469e-03, 3.32083702e-03,\n",
       "        3.40247154e-03, 3.75428200e-03, 6.27584457e-03, 1.04079247e-03,\n",
       "        4.06842232e-03, 4.75316048e-03, 2.05636024e-03, 5.89008331e-03,\n",
       "        1.07383728e-03, 1.39985085e-03, 6.71148300e-03, 3.80654335e-03,\n",
       "        3.18498611e-03, 3.33042145e-03, 1.57880783e-04, 4.26478386e-03,\n",
       "        0.00000000e+00, 1.24374390e-02, 3.79328728e-03, 3.35931778e-03,\n",
       "        7.48920441e-04, 1.66082382e-03, 4.73275185e-03, 9.82809067e-04,\n",
       "        3.94330025e-03, 3.65157127e-03, 4.34918404e-03, 7.80801773e-03,\n",
       "        3.90763283e-03, 0.00000000e+00, 3.47476006e-03, 4.36277390e-03,\n",
       "        4.94031906e-03, 3.11150551e-03, 0.00000000e+00, 4.75201607e-03,\n",
       "        6.50167465e-03, 6.32190704e-03, 3.17478180e-04, 6.48083687e-03,\n",
       "        5.36441803e-04, 4.38208580e-03, 1.13226414e-02, 6.03532791e-04,\n",
       "        9.61775780e-03, 3.52182388e-03, 6.54773712e-03, 1.03807926e-02,\n",
       "        3.12795639e-03, 0.00000000e+00, 3.00855637e-03, 6.62555695e-03,\n",
       "        1.14936352e-02, 3.33976746e-03, 5.49302101e-03, 4.93288040e-04,\n",
       "        6.25486374e-03, 1.12780571e-02, 3.35574150e-03, 2.98643112e-03,\n",
       "        6.82587624e-03, 3.04412842e-03, 3.80253792e-03, 3.04846764e-03,\n",
       "        0.00000000e+00, 4.60987091e-03, 2.00438499e-03, 4.74863052e-03,\n",
       "        6.98909760e-03, 4.01306152e-04, 9.31978226e-04, 5.40442467e-03,\n",
       "        1.28386497e-02, 0.00000000e+00, 3.12476158e-03, 0.00000000e+00,\n",
       "        2.00090408e-03, 4.69069481e-03, 0.00000000e+00, 3.12500000e-03,\n",
       "        0.00000000e+00, 4.32562828e-03, 3.12500000e-03, 3.12519073e-03,\n",
       "        3.12628746e-03, 0.00000000e+00, 4.15430069e-03, 9.37433243e-03,\n",
       "        1.25000000e-02, 3.12504768e-03, 7.45525360e-03, 4.16760445e-03,\n",
       "        1.25000477e-02, 3.52344513e-03, 0.00000000e+00, 3.10101509e-03,\n",
       "        1.18728161e-02, 6.67157173e-03, 3.41458321e-03, 5.22613525e-05,\n",
       "        3.89146805e-03, 9.98830795e-03, 3.81541252e-03, 3.39660645e-03,\n",
       "        6.21695518e-03, 6.62097931e-03, 6.65807724e-03, 1.13045216e-02,\n",
       "        0.00000000e+00, 6.80570602e-03, 3.30138206e-03, 1.05664730e-02,\n",
       "        1.11966133e-02, 2.01892853e-03, 8.03995132e-04, 7.99894333e-04,\n",
       "        6.43582344e-03, 3.82871628e-03, 2.01587677e-03, 4.00686264e-04,\n",
       "        4.54058647e-03, 3.12523842e-03, 6.67104721e-03, 3.27749252e-03,\n",
       "        3.33533287e-03, 3.20215225e-03, 4.40440178e-03, 4.78343964e-03,\n",
       "        2.00939178e-04, 3.75318527e-03, 1.40094757e-03, 6.46386147e-03,\n",
       "        3.33037376e-03, 3.69648933e-03, 3.58319283e-03, 4.14896011e-03,\n",
       "        2.82292366e-03, 4.72345352e-03, 2.89483070e-03, 4.99677658e-04,\n",
       "        7.10716248e-03, 2.89859772e-03, 9.94262695e-03, 1.51920319e-03,\n",
       "        1.35293007e-03, 3.39355469e-03, 3.53422165e-03, 6.73184395e-03]),\n",
       " 'std_score_time': array([7.87398149e-04, 8.00132751e-04, 1.46958733e-03, 7.47900942e-03,\n",
       "        6.09873825e-03, 4.67681885e-04, 1.16394163e-03, 6.51311874e-03,\n",
       "        7.66300675e-03, 4.21978925e-03, 6.25019073e-03, 1.37476589e-03,\n",
       "        6.66828156e-03, 9.01670602e-04, 6.25009537e-03, 0.00000000e+00,\n",
       "        2.03981400e-03, 7.80178606e-03, 0.00000000e+00, 6.13478709e-03,\n",
       "        6.26974106e-03, 6.20183945e-03, 6.25009537e-03, 7.04590506e-03,\n",
       "        5.13153242e-03, 5.23684203e-03, 6.24990463e-03, 0.00000000e+00,\n",
       "        7.94019345e-03, 5.75503911e-03, 6.50469746e-03, 1.19943619e-03,\n",
       "        1.41900639e-03, 6.24638978e-03, 8.05197793e-03, 6.25057220e-03,\n",
       "        5.59567669e-03, 6.66255951e-03, 8.10001603e-03, 7.21254604e-03,\n",
       "        0.00000000e+00, 4.33540344e-04, 5.89958626e-03, 7.76466695e-03,\n",
       "        8.39280165e-03, 6.44368107e-03, 6.64806366e-03, 6.12895278e-03,\n",
       "        5.73975030e-03, 7.25006273e-03, 9.79491466e-04, 6.09802134e-03,\n",
       "        1.56374313e-03, 7.54856293e-03, 5.80434101e-03, 7.77073186e-04,\n",
       "        6.25028610e-03, 6.22286232e-03, 2.36303147e-03, 7.89892308e-03,\n",
       "        6.61373138e-03, 6.25038147e-03, 6.00767136e-03, 0.00000000e+00,\n",
       "        3.48758698e-03, 6.47125244e-03, 6.70642853e-03, 7.66300889e-03,\n",
       "        7.67249169e-03, 8.10927997e-03, 5.45792239e-03, 5.28929024e-03,\n",
       "        6.61436553e-03, 0.00000000e+00, 8.20443067e-03, 9.61751855e-04,\n",
       "        0.00000000e+00, 8.41140747e-04, 5.48454500e-03, 7.66269738e-03,\n",
       "        1.33619308e-03, 7.65436345e-03, 6.13325403e-03, 5.72394997e-03,\n",
       "        6.99121523e-03, 0.00000000e+00, 6.06334770e-03, 5.82650336e-03,\n",
       "        6.10808876e-03, 7.83608976e-03, 6.25000000e-03, 2.07557678e-03,\n",
       "        6.25009537e-03, 6.25000000e-03, 5.60479680e-03, 0.00000000e+00,\n",
       "        6.25028610e-03, 7.65430505e-03, 5.92447647e-03, 5.89858980e-03,\n",
       "        0.00000000e+00, 2.02660029e-03, 2.64711380e-03, 8.04047208e-03,\n",
       "        3.90332024e-03, 5.27014078e-03, 7.42738701e-04, 4.83753565e-04,\n",
       "        7.37380981e-03, 1.53169632e-03, 7.11154938e-04, 9.79841695e-04,\n",
       "        6.06229562e-03, 7.02438827e-03, 7.65459705e-03, 7.65471386e-03,\n",
       "        1.19915009e-03, 6.22106709e-03, 4.19087567e-03, 7.65483065e-03,\n",
       "        6.24980927e-03, 0.00000000e+00, 0.00000000e+00, 6.24980927e-03,\n",
       "        7.65453865e-03, 0.00000000e+00, 7.65453865e-03, 6.26449585e-03,\n",
       "        7.65494745e-03, 5.76493679e-03, 8.48793654e-04, 5.32623901e-03,\n",
       "        6.91005343e-03, 7.65473334e-03, 6.46934034e-03, 6.25000000e-03,\n",
       "        1.26448012e-03, 1.57416266e-03, 8.18062554e-03, 8.16152468e-03,\n",
       "        5.82036972e-03, 6.66856766e-03, 6.74991608e-03, 5.04786275e-03,\n",
       "        6.60448074e-03, 1.10835198e-03, 6.12882477e-03, 1.67708515e-03,\n",
       "        6.63282913e-03, 4.84220170e-03, 6.91318512e-04, 0.00000000e+00,\n",
       "        6.01768494e-04, 6.96169713e-03, 6.43576911e-03, 6.09946322e-03,\n",
       "        3.16809557e-03, 6.06257072e-03, 6.17364768e-03, 6.42357647e-03,\n",
       "        0.00000000e+00, 6.10414000e-03, 1.76322478e-03, 6.06739673e-03,\n",
       "        7.63531498e-03, 6.25000000e-03, 7.65442186e-03, 1.65877625e-03,\n",
       "        7.37519611e-03, 7.65471385e-03, 0.00000000e+00, 2.45893844e-03,\n",
       "        1.53545139e-03, 6.27409836e-03, 7.90886526e-03, 6.25009537e-03,\n",
       "        6.09909676e-03, 6.24990463e-03, 5.91830475e-03, 5.83460763e-03,\n",
       "        0.00000000e+00, 8.00230804e-04, 5.74040472e-03, 4.69540215e-03,\n",
       "        3.85019796e-03, 6.84100828e-03, 1.46970412e-03, 7.65448026e-03,\n",
       "        4.69941963e-03, 3.13791427e-03, 6.25019073e-03, 6.24980927e-03,\n",
       "        6.09873979e-03, 7.58881620e-03, 7.22513808e-03, 8.00037384e-04,\n",
       "        9.96519768e-04, 7.62531633e-03, 5.75692378e-03, 6.05172186e-03,\n",
       "        0.00000000e+00, 6.24990463e-03, 1.43222809e-03, 6.25000000e-03,\n",
       "        6.25028610e-03, 6.24961853e-03, 7.65512265e-03, 0.00000000e+00,\n",
       "        6.02105769e-03, 7.65477225e-03, 6.25190735e-03, 6.25019073e-03,\n",
       "        7.91478799e-03, 4.94956970e-05, 5.27511530e-03, 9.24502544e-04,\n",
       "        6.24990463e-03, 7.24789928e-03, 7.66219527e-03, 7.06464094e-03,\n",
       "        7.54934766e-04, 1.16305493e-03, 6.18684793e-03, 5.10982474e-03,\n",
       "        3.24146503e-03, 4.90687143e-03, 4.60949536e-03, 1.50310135e-03,\n",
       "        2.31572623e-03, 1.16391115e-04, 4.14756723e-03, 3.13197289e-03,\n",
       "        1.34438306e-03, 2.65089127e-03, 3.95995716e-03, 9.80621912e-04,\n",
       "        2.75847512e-03, 6.06286293e-03, 1.13758932e-03, 6.21241261e-03,\n",
       "        4.70381254e-03, 1.46989883e-03, 6.06690044e-03, 3.98738000e-03,\n",
       "        2.71778978e-03, 4.38674937e-03, 1.19990510e-03, 5.48409711e-03,\n",
       "        2.50727134e-03, 6.89245462e-03, 9.19144293e-04, 9.80855965e-04,\n",
       "        1.38505238e-03, 4.83110441e-03, 3.28407922e-03, 3.24376670e-04,\n",
       "        1.31756761e-03, 4.31080290e-03, 2.57440059e-03, 7.65453865e-03,\n",
       "        5.91792239e-03, 0.00000000e+00, 7.23269109e-03, 5.95395218e-03,\n",
       "        1.83203225e-03, 4.04323826e-03, 4.97691363e-03, 4.36246538e-03,\n",
       "        5.60995876e-03, 6.06635079e-03, 1.10013773e-03, 6.41569485e-04,\n",
       "        1.43708453e-03, 4.69788169e-03, 2.74645675e-03, 5.39096686e-03,\n",
       "        5.81732224e-03, 1.60571805e-03, 6.75408828e-03, 3.58140781e-04,\n",
       "        9.79415147e-04, 6.34430020e-04, 1.65981917e-03, 2.29263144e-03,\n",
       "        6.50546295e-03, 7.83888246e-04, 7.01574100e-04, 7.75523976e-03,\n",
       "        4.67964256e-03, 6.05806052e-03, 6.51501681e-03, 1.26487790e-03,\n",
       "        4.12348373e-04, 6.55780983e-03, 7.52664884e-03, 0.00000000e+00,\n",
       "        4.30679321e-03, 1.84964642e-03, 2.21465370e-03, 3.07582278e-03,\n",
       "        8.96892385e-04, 5.37499590e-03, 6.72209342e-03, 6.80847436e-03,\n",
       "        8.40155484e-03, 5.94003875e-03, 0.00000000e+00, 7.24798234e-03,\n",
       "        7.95887577e-03, 4.58978026e-03, 5.99622850e-04, 1.45212842e-03,\n",
       "        5.73616933e-03, 4.71277823e-03, 6.33924751e-03, 7.43309537e-03,\n",
       "        7.65465545e-03, 0.00000000e+00, 5.94640514e-03, 6.11091538e-03,\n",
       "        0.00000000e+00, 6.24990463e-03, 5.79516611e-03, 2.06349292e-03,\n",
       "        5.79890838e-03, 0.00000000e+00, 1.41866284e-03, 1.60026550e-03,\n",
       "        2.83708542e-03, 7.85065244e-03, 1.00951953e-03, 7.28969688e-03,\n",
       "        6.57436496e-04, 7.07870223e-03, 6.24031274e-03, 9.79608093e-04,\n",
       "        1.15951832e-03, 6.06248282e-03, 5.08637314e-03, 6.57886161e-03,\n",
       "        6.25000000e-03, 5.79748566e-03, 5.67888890e-03, 2.45516382e-03,\n",
       "        2.61182439e-03, 5.83426373e-03, 5.52698611e-03, 5.57133874e-03,\n",
       "        2.12964151e-03, 6.40047794e-03, 0.00000000e+00, 5.95915148e-03,\n",
       "        1.74347157e-03, 7.88431608e-03, 7.17529123e-03, 9.75868108e-04,\n",
       "        9.73711712e-04, 1.65157708e-03, 2.04337722e-03, 8.15029785e-03,\n",
       "        9.79666485e-04, 1.02168676e-03, 3.62155056e-04, 4.80652845e-03,\n",
       "        5.76902508e-03, 8.94255906e-04, 9.79958495e-04, 6.05875834e-03,\n",
       "        6.26187827e-03, 6.73796286e-03, 9.79686069e-04, 4.96039498e-03,\n",
       "        5.89278916e-03, 2.37386919e-03, 3.57419302e-03, 9.79900110e-04,\n",
       "        7.65483065e-03, 0.00000000e+00, 7.65442185e-03, 5.80940596e-03,\n",
       "        6.00916647e-03, 7.03058802e-03, 1.50251995e-03, 2.13541507e-03,\n",
       "        3.05398225e-03, 5.53314409e-03, 5.92090975e-04, 5.32995489e-03,\n",
       "        5.71440682e-03, 6.25000006e-03, 0.00000000e+00, 7.99274445e-04,\n",
       "        6.09903650e-03, 6.63347015e-03, 6.46055951e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 6.05174414e-03, 6.06773520e-03, 6.32595976e-07,\n",
       "        0.00000000e+00, 6.07407388e-03, 1.56811278e-03, 2.00014114e-03,\n",
       "        4.98429141e-03, 0.00000000e+00, 0.00000000e+00, 6.64263960e-03,\n",
       "        3.90783822e-04, 3.74266466e-03, 9.79686254e-04, 1.06314222e-03,\n",
       "        1.17918680e-03, 5.09357078e-03, 3.77806590e-03, 9.80075435e-04,\n",
       "        1.58773100e-03, 5.76794731e-03, 6.80465223e-03, 8.71570320e-03,\n",
       "        0.00000000e+00, 6.25019073e-03, 0.00000000e+00, 7.65481118e-03,\n",
       "        7.08948655e-03, 1.02750211e-03, 5.38776837e-03, 1.88479287e-03,\n",
       "        5.12189262e-03, 5.70652805e-03, 9.79958495e-04, 1.26489478e-03,\n",
       "        1.51326665e-03, 6.29172954e-03, 6.82705493e-03, 4.00066376e-04,\n",
       "        4.85257255e-04, 1.93967819e-03, 6.57640285e-03, 4.32217451e-03,\n",
       "        1.34506226e-03, 6.00271225e-03, 6.44180964e-03, 7.65477226e-03,\n",
       "        6.25000000e-03, 0.00000000e+00, 0.00000000e+00, 1.74401897e-03,\n",
       "        4.89413502e-03, 6.98760654e-03, 0.00000000e+00, 6.25009537e-03,\n",
       "        3.13795483e-03, 2.73521240e-03, 6.84286118e-03, 4.92988860e-03,\n",
       "        1.35707810e-03, 4.45411903e-03, 2.19604825e-03, 4.92224544e-03,\n",
       "        1.03073800e-03, 9.79024925e-04, 5.91714829e-03, 2.20163201e-03,\n",
       "        5.34460950e-03, 6.06287434e-03, 8.94427233e-04, 6.74647269e-03,\n",
       "        5.97627613e-03, 6.14346199e-03, 9.47760660e-04, 1.02814412e-03,\n",
       "        4.83282084e-03, 6.36099943e-03, 2.09282079e-03, 8.95856762e-04,\n",
       "        4.93910822e-03, 1.61360624e-03, 5.74872706e-03, 3.01381340e-03,\n",
       "        5.80895903e-03, 1.03562289e-03, 4.69277137e-04, 5.02679077e-03,\n",
       "        3.77588704e-03, 4.69884872e-03, 6.61936036e-03, 5.26829354e-03,\n",
       "        5.34021031e-04, 3.65852988e-03, 4.48876747e-04, 4.72003392e-03,\n",
       "        2.90265744e-04, 2.68111124e-03, 4.51907906e-03, 8.98088991e-04,\n",
       "        6.20236770e-03, 4.25530054e-03, 2.51999573e-03, 5.31873529e-03,\n",
       "        9.35768789e-04, 1.19988921e-03, 6.85111804e-03, 5.46715620e-03,\n",
       "        3.26280966e-03, 6.41203930e-03, 3.15761566e-04, 5.82227387e-03,\n",
       "        0.00000000e+00, 3.97252123e-03, 5.65708970e-03, 5.82788163e-03,\n",
       "        1.16310948e-03, 2.34580783e-03, 6.36192343e-03, 8.95538629e-04,\n",
       "        5.51054479e-03, 6.48252926e-03, 5.65158517e-03, 7.14638025e-03,\n",
       "        5.68680636e-03, 0.00000000e+00, 6.59149018e-03, 6.52059607e-03,\n",
       "        6.63207249e-03, 5.98395281e-03, 0.00000000e+00, 6.34517055e-03,\n",
       "        7.96367446e-03, 7.75830255e-03, 6.34956360e-04, 7.93738561e-03,\n",
       "        1.07288361e-03, 6.37152629e-03, 5.65036939e-03, 8.06147753e-04,\n",
       "        7.89091636e-03, 6.00152351e-03, 7.15495976e-03, 7.46269476e-03,\n",
       "        5.50254929e-03, 0.00000000e+00, 6.01711273e-03, 7.80703992e-03,\n",
       "        6.83229080e-03, 6.67953491e-03, 6.72834567e-03, 6.70494189e-04,\n",
       "        7.67102690e-03, 6.67174781e-03, 6.71148300e-03, 5.97286224e-03,\n",
       "        8.07643358e-03, 6.08825684e-03, 6.41841793e-03, 6.09693527e-03,\n",
       "        0.00000000e+00, 6.13702426e-03, 2.14781140e-03, 6.58222026e-03,\n",
       "        7.09720758e-03, 8.02612305e-04, 1.55533797e-03, 5.71367808e-03,\n",
       "        6.45277309e-03, 0.00000000e+00, 6.24952316e-03, 0.00000000e+00,\n",
       "        4.00180817e-03, 9.38138962e-03, 0.00000000e+00, 6.25000000e-03,\n",
       "        0.00000000e+00, 6.10968715e-03, 6.25000000e-03, 6.25038147e-03,\n",
       "        6.25257492e-03, 0.00000000e+00, 5.86738789e-03, 7.65411055e-03,\n",
       "        6.25000028e-03, 6.25009537e-03, 7.02421103e-03, 6.07382414e-03,\n",
       "        6.25002386e-03, 6.59786181e-03, 0.00000000e+00, 6.20203018e-03,\n",
       "        7.18769194e-03, 8.17097364e-03, 6.61492499e-03, 1.04522705e-04,\n",
       "        6.50121108e-03, 8.15559558e-03, 7.50462951e-03, 5.58778436e-03,\n",
       "        7.64915978e-03, 8.10935954e-03, 8.15462664e-03, 6.61158048e-03,\n",
       "        0.00000000e+00, 8.33861482e-03, 6.60276413e-03, 8.78207179e-03,\n",
       "        6.62559975e-03, 2.83192340e-04, 9.84710762e-04, 1.59978867e-03,\n",
       "        6.52250758e-03, 6.45212502e-03, 3.51906445e-03, 8.01372528e-04,\n",
       "        5.76413271e-03, 6.25047684e-03, 8.17033522e-03, 6.55498505e-03,\n",
       "        6.53290806e-03, 5.66635466e-03, 6.30888505e-03, 6.51678504e-03,\n",
       "        4.01878357e-04, 6.54357647e-03, 1.74491575e-03, 7.53902658e-03,\n",
       "        6.66074753e-03, 6.43969214e-03, 6.06747880e-03, 6.42248760e-03,\n",
       "        5.64584732e-03, 6.55811342e-03, 5.78966141e-03, 9.99355316e-04,\n",
       "        7.77143257e-03, 5.65734300e-03, 8.11883087e-03, 2.22968588e-03,\n",
       "        9.74459715e-04, 6.65734308e-03, 6.56490825e-03, 8.13867494e-03]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.66666667, 0.65625   , 0.63541667, 0.63541667, 0.60416667,\n",
       "        0.625     , 0.59375   , 0.66666667, 0.64583333, 0.64583333,\n",
       "        0.65625   , 0.61458333, 0.60416667, 0.65625   , 0.63541667,\n",
       "        0.63541667, 0.69791667, 0.61458333, 0.66666667, 0.61458333,\n",
       "        0.61458333, 0.64583333, 0.6875    , 0.61458333, 0.65625   ,\n",
       "        0.6875    , 0.65625   , 0.60416667, 0.63541667, 0.65625   ,\n",
       "        0.6875    , 0.625     , 0.66666667, 0.625     , 0.65625   ,\n",
       "        0.58333333, 0.63541667, 0.66666667, 0.65625   , 0.67708333,\n",
       "        0.70833333, 0.60416667, 0.63541667, 0.66666667, 0.625     ,\n",
       "        0.625     , 0.65625   , 0.65625   , 0.625     , 0.625     ,\n",
       "        0.60416667, 0.69791667, 0.65625   , 0.66666667, 0.61458333,\n",
       "        0.60416667, 0.59375   , 0.64583333, 0.59375   , 0.625     ,\n",
       "        0.66666667, 0.59375   , 0.61458333, 0.64583333, 0.625     ,\n",
       "        0.67708333, 0.69791667, 0.64583333, 0.61458333, 0.63541667,\n",
       "        0.59375   , 0.61458333, 0.60416667, 0.60416667, 0.63541667,\n",
       "        0.67708333, 0.64583333, 0.67708333, 0.61458333, 0.625     ,\n",
       "        0.59375   , 0.625     , 0.60416667, 0.66666667, 0.61458333,\n",
       "        0.64583333, 0.66666667, 0.65625   , 0.64583333, 0.64583333,\n",
       "        0.6875    , 0.64583333, 0.63541667, 0.66666667, 0.64583333,\n",
       "        0.625     , 0.69791667, 0.61458333, 0.63541667, 0.64583333,\n",
       "        0.67708333, 0.6875    , 0.65625   , 0.64583333, 0.65625   ,\n",
       "        0.625     , 0.65625   , 0.65625   , 0.625     , 0.63541667,\n",
       "        0.66666667, 0.58333333, 0.67708333, 0.64583333, 0.63541667,\n",
       "        0.65625   , 0.60416667, 0.64583333, 0.65625   , 0.65625   ,\n",
       "        0.69791667, 0.70833333, 0.6875    , 0.61458333, 0.60416667,\n",
       "        0.64583333, 0.67708333, 0.60416667, 0.64583333, 0.66666667,\n",
       "        0.66666667, 0.65625   , 0.67708333, 0.63541667, 0.625     ,\n",
       "        0.63541667, 0.67708333, 0.625     , 0.63541667, 0.63541667,\n",
       "        0.57291667, 0.60416667, 0.55208333, 0.63541667, 0.625     ,\n",
       "        0.66666667, 0.64583333, 0.66666667, 0.63541667, 0.63541667,\n",
       "        0.61458333, 0.6875    , 0.65625   , 0.63541667, 0.63541667,\n",
       "        0.57291667, 0.59375   , 0.60416667, 0.63541667, 0.65625   ,\n",
       "        0.66666667, 0.57291667, 0.61458333, 0.625     , 0.65625   ,\n",
       "        0.60416667, 0.67708333, 0.60416667, 0.64583333, 0.63541667,\n",
       "        0.60416667, 0.61458333, 0.64583333, 0.65625   , 0.67708333,\n",
       "        0.64583333, 0.63541667, 0.6875    , 0.61458333, 0.65625   ,\n",
       "        0.625     , 0.67708333, 0.59375   , 0.65625   , 0.65625   ,\n",
       "        0.64583333, 0.61458333, 0.65625   , 0.59375   , 0.67708333,\n",
       "        0.59375   , 0.64583333, 0.60416667, 0.64583333, 0.63541667,\n",
       "        0.6875    , 0.61458333, 0.65625   , 0.66666667, 0.64583333,\n",
       "        0.66666667, 0.66666667, 0.65625   , 0.61458333, 0.65625   ,\n",
       "        0.63541667, 0.60416667, 0.61458333, 0.66666667, 0.625     ,\n",
       "        0.60416667, 0.64583333, 0.61458333, 0.66666667, 0.625     ,\n",
       "        0.69791667, 0.59375   , 0.63541667, 0.63541667, 0.61458333,\n",
       "        0.66666667, 0.66666667, 0.64583333, 0.58333333, 0.625     ,\n",
       "        0.64583333, 0.63541667, 0.65625   , 0.64583333, 0.61458333,\n",
       "        0.63541667, 0.6875    , 0.64583333, 0.63541667, 0.625     ,\n",
       "        0.69791667, 0.61458333, 0.67708333, 0.61458333, 0.63541667,\n",
       "        0.65625   , 0.625     , 0.66666667, 0.625     , 0.66666667,\n",
       "        0.64583333, 0.64583333, 0.60416667, 0.63541667, 0.625     ,\n",
       "        0.625     , 0.70833333, 0.63541667, 0.67708333, 0.64583333,\n",
       "        0.64583333, 0.625     , 0.66666667, 0.625     , 0.64583333,\n",
       "        0.63541667, 0.6875    , 0.625     , 0.66666667, 0.63541667,\n",
       "        0.61458333, 0.67708333, 0.64583333, 0.63541667, 0.67708333,\n",
       "        0.58333333, 0.60416667, 0.66666667, 0.64583333, 0.64583333,\n",
       "        0.63541667, 0.70833333, 0.69791667, 0.625     , 0.65625   ,\n",
       "        0.66666667, 0.63541667, 0.63541667, 0.625     , 0.61458333,\n",
       "        0.625     , 0.625     , 0.65625   , 0.64583333, 0.61458333,\n",
       "        0.625     , 0.64583333, 0.64583333, 0.64583333, 0.63541667,\n",
       "        0.59375   , 0.625     , 0.625     , 0.64583333, 0.64583333,\n",
       "        0.54166667, 0.59375   , 0.61458333, 0.625     , 0.625     ,\n",
       "        0.6875    , 0.66666667, 0.64583333, 0.63541667, 0.60416667,\n",
       "        0.67708333, 0.71875   , 0.625     , 0.66666667, 0.61458333,\n",
       "        0.67708333, 0.65625   , 0.61458333, 0.59375   , 0.63541667,\n",
       "        0.64583333, 0.64583333, 0.59375   , 0.60416667, 0.625     ,\n",
       "        0.60416667, 0.67708333, 0.61458333, 0.65625   , 0.64583333,\n",
       "        0.66666667, 0.63541667, 0.63541667, 0.6875    , 0.66666667,\n",
       "        0.66666667, 0.71875   , 0.6875    , 0.69791667, 0.66666667,\n",
       "        0.64583333, 0.69791667, 0.65625   , 0.64583333, 0.61458333,\n",
       "        0.63541667, 0.64583333, 0.63541667, 0.65625   , 0.63541667,\n",
       "        0.63541667, 0.69791667, 0.70833333, 0.64583333, 0.63541667,\n",
       "        0.70833333, 0.66666667, 0.67708333, 0.61458333, 0.64583333,\n",
       "        0.66666667, 0.67708333, 0.59375   , 0.63541667, 0.67708333,\n",
       "        0.65625   , 0.65625   , 0.625     , 0.625     , 0.66666667,\n",
       "        0.72916667, 0.66666667, 0.61458333, 0.64583333, 0.63541667,\n",
       "        0.72916667, 0.64583333, 0.63541667, 0.66666667, 0.64583333,\n",
       "        0.71875   , 0.57291667, 0.63541667, 0.63541667, 0.625     ,\n",
       "        0.73958333, 0.63541667, 0.6875    , 0.63541667, 0.60416667,\n",
       "        0.61458333, 0.66666667, 0.65625   , 0.63541667, 0.61458333,\n",
       "        0.59375   , 0.70833333, 0.6875    , 0.65625   , 0.63541667,\n",
       "        0.63541667, 0.63541667, 0.66666667, 0.63541667, 0.65625   ,\n",
       "        0.65625   , 0.58333333, 0.63541667, 0.64583333, 0.63541667,\n",
       "        0.63541667, 0.63541667, 0.6875    , 0.66666667, 0.63541667,\n",
       "        0.64583333, 0.625     , 0.66666667, 0.625     , 0.6875    ,\n",
       "        0.59375   , 0.65625   , 0.625     , 0.64583333, 0.63541667,\n",
       "        0.59375   , 0.63541667, 0.63541667, 0.63541667, 0.66666667,\n",
       "        0.64583333, 0.65625   , 0.63541667, 0.64583333, 0.625     ,\n",
       "        0.5625    , 0.67708333, 0.64583333, 0.66666667, 0.64583333,\n",
       "        0.66666667, 0.65625   , 0.66666667, 0.64583333, 0.58333333,\n",
       "        0.55208333, 0.70833333, 0.64583333, 0.65625   , 0.61458333,\n",
       "        0.65625   , 0.64583333, 0.64583333, 0.60416667, 0.64583333,\n",
       "        0.70833333, 0.63541667, 0.65625   , 0.63541667, 0.63541667,\n",
       "        0.60416667, 0.63541667, 0.625     , 0.625     , 0.625     ,\n",
       "        0.69791667, 0.64583333, 0.66666667, 0.63541667, 0.625     ,\n",
       "        0.61458333, 0.59375   , 0.61458333, 0.63541667, 0.66666667,\n",
       "        0.6875    , 0.65625   , 0.64583333, 0.63541667, 0.64583333,\n",
       "        0.65625   , 0.6875    , 0.65625   , 0.65625   , 0.63541667,\n",
       "        0.625     , 0.66666667, 0.67708333, 0.67708333, 0.61458333,\n",
       "        0.6875    , 0.625     , 0.65625   , 0.61458333, 0.64583333,\n",
       "        0.625     , 0.63541667, 0.64583333, 0.67708333, 0.625     ,\n",
       "        0.63541667, 0.65625   , 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.67708333, 0.67708333, 0.65625   , 0.66666667, 0.63541667,\n",
       "        0.63541667, 0.66666667, 0.64583333, 0.67708333, 0.625     ,\n",
       "        0.6875    , 0.67708333, 0.69791667, 0.66666667, 0.625     ,\n",
       "        0.65625   , 0.59375   , 0.625     , 0.625     , 0.625     ,\n",
       "        0.64583333, 0.59375   , 0.64583333, 0.61458333, 0.64583333,\n",
       "        0.58333333, 0.63541667, 0.67708333, 0.63541667, 0.65625   ,\n",
       "        0.63541667, 0.65625   , 0.61458333, 0.61458333, 0.67708333,\n",
       "        0.625     , 0.69791667, 0.57291667, 0.625     , 0.61458333,\n",
       "        0.66666667, 0.625     , 0.64583333, 0.64583333, 0.63541667,\n",
       "        0.60416667, 0.60416667, 0.59375   , 0.67708333, 0.63541667,\n",
       "        0.67708333, 0.67708333, 0.60416667, 0.64583333, 0.60416667,\n",
       "        0.60416667, 0.6875    , 0.61458333, 0.67708333, 0.63541667,\n",
       "        0.60416667, 0.64583333, 0.63541667, 0.63541667, 0.65625   ,\n",
       "        0.67708333, 0.65625   , 0.60416667, 0.67708333, 0.67708333,\n",
       "        0.66666667, 0.65625   , 0.6875    , 0.63541667, 0.65625   ,\n",
       "        0.6875    , 0.66666667, 0.63541667, 0.65625   , 0.65625   ,\n",
       "        0.57291667, 0.60416667, 0.63541667, 0.65625   , 0.67708333,\n",
       "        0.625     , 0.66666667, 0.66666667, 0.66666667, 0.63541667,\n",
       "        0.69791667, 0.64583333, 0.65625   , 0.66666667, 0.67708333,\n",
       "        0.64583333, 0.60416667, 0.60416667, 0.65625   , 0.63541667,\n",
       "        0.625     , 0.58333333, 0.64583333, 0.65625   , 0.65625   ,\n",
       "        0.69791667, 0.70833333, 0.625     , 0.65625   , 0.59375   ,\n",
       "        0.66666667, 0.58333333, 0.61458333, 0.63541667, 0.65625   ,\n",
       "        0.57291667, 0.60416667, 0.61458333, 0.61458333, 0.61458333,\n",
       "        0.71875   , 0.73958333, 0.64583333, 0.66666667, 0.64583333,\n",
       "        0.57291667, 0.625     , 0.60416667, 0.65625   , 0.65625   ,\n",
       "        0.625     , 0.65625   , 0.66666667, 0.64583333, 0.625     ]),\n",
       " 'split1_test_score': array([0.70833333, 0.59375   , 0.63541667, 0.64583333, 0.625     ,\n",
       "        0.625     , 0.63541667, 0.64583333, 0.61458333, 0.63541667,\n",
       "        0.70833333, 0.67708333, 0.64583333, 0.625     , 0.63541667,\n",
       "        0.65625   , 0.67708333, 0.65625   , 0.64583333, 0.66666667,\n",
       "        0.69791667, 0.64583333, 0.67708333, 0.64583333, 0.64583333,\n",
       "        0.64583333, 0.67708333, 0.65625   , 0.65625   , 0.65625   ,\n",
       "        0.70833333, 0.66666667, 0.63541667, 0.66666667, 0.66666667,\n",
       "        0.71875   , 0.72916667, 0.67708333, 0.66666667, 0.66666667,\n",
       "        0.75      , 0.6875    , 0.67708333, 0.70833333, 0.72916667,\n",
       "        0.66666667, 0.70833333, 0.69791667, 0.69791667, 0.71875   ,\n",
       "        0.61458333, 0.67708333, 0.72916667, 0.6875    , 0.71875   ,\n",
       "        0.63541667, 0.66666667, 0.73958333, 0.69791667, 0.69791667,\n",
       "        0.70833333, 0.64583333, 0.69791667, 0.70833333, 0.65625   ,\n",
       "        0.69791667, 0.67708333, 0.71875   , 0.70833333, 0.6875    ,\n",
       "        0.75      , 0.6875    , 0.67708333, 0.6875    , 0.6875    ,\n",
       "        0.70833333, 0.72916667, 0.70833333, 0.6875    , 0.72916667,\n",
       "        0.625     , 0.64583333, 0.63541667, 0.625     , 0.63541667,\n",
       "        0.67708333, 0.6875    , 0.64583333, 0.63541667, 0.61458333,\n",
       "        0.61458333, 0.63541667, 0.67708333, 0.65625   , 0.63541667,\n",
       "        0.69791667, 0.65625   , 0.64583333, 0.63541667, 0.63541667,\n",
       "        0.66666667, 0.65625   , 0.625     , 0.64583333, 0.64583333,\n",
       "        0.70833333, 0.64583333, 0.69791667, 0.64583333, 0.67708333,\n",
       "        0.6875    , 0.625     , 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.75      , 0.67708333, 0.69791667, 0.66666667, 0.66666667,\n",
       "        0.72916667, 0.75      , 0.67708333, 0.69791667, 0.66666667,\n",
       "        0.72916667, 0.69791667, 0.69791667, 0.71875   , 0.67708333,\n",
       "        0.66666667, 0.65625   , 0.64583333, 0.72916667, 0.72916667,\n",
       "        0.70833333, 0.69791667, 0.71875   , 0.65625   , 0.6875    ,\n",
       "        0.66666667, 0.73958333, 0.69791667, 0.71875   , 0.67708333,\n",
       "        0.64583333, 0.71875   , 0.71875   , 0.70833333, 0.67708333,\n",
       "        0.66666667, 0.69791667, 0.6875    , 0.66666667, 0.69791667,\n",
       "        0.69791667, 0.72916667, 0.71875   , 0.72916667, 0.70833333,\n",
       "        0.55208333, 0.59375   , 0.59375   , 0.625     , 0.58333333,\n",
       "        0.64583333, 0.70833333, 0.61458333, 0.64583333, 0.64583333,\n",
       "        0.64583333, 0.63541667, 0.67708333, 0.63541667, 0.63541667,\n",
       "        0.67708333, 0.66666667, 0.64583333, 0.67708333, 0.64583333,\n",
       "        0.67708333, 0.67708333, 0.67708333, 0.6875    , 0.6875    ,\n",
       "        0.64583333, 0.67708333, 0.67708333, 0.69791667, 0.69791667,\n",
       "        0.66666667, 0.66666667, 0.65625   , 0.67708333, 0.64583333,\n",
       "        0.69791667, 0.71875   , 0.69791667, 0.69791667, 0.66666667,\n",
       "        0.73958333, 0.6875    , 0.6875    , 0.65625   , 0.70833333,\n",
       "        0.61458333, 0.66666667, 0.69791667, 0.67708333, 0.65625   ,\n",
       "        0.75      , 0.73958333, 0.67708333, 0.69791667, 0.69791667,\n",
       "        0.65625   , 0.70833333, 0.64583333, 0.66666667, 0.6875    ,\n",
       "        0.67708333, 0.66666667, 0.71875   , 0.78125   , 0.67708333,\n",
       "        0.73958333, 0.69791667, 0.65625   , 0.71875   , 0.66666667,\n",
       "        0.6875    , 0.72916667, 0.76041667, 0.66666667, 0.67708333,\n",
       "        0.69791667, 0.71875   , 0.66666667, 0.70833333, 0.71875   ,\n",
       "        0.58333333, 0.64583333, 0.66666667, 0.63541667, 0.61458333,\n",
       "        0.65625   , 0.66666667, 0.64583333, 0.63541667, 0.65625   ,\n",
       "        0.60416667, 0.63541667, 0.65625   , 0.65625   , 0.65625   ,\n",
       "        0.64583333, 0.63541667, 0.66666667, 0.66666667, 0.6875    ,\n",
       "        0.625     , 0.6875    , 0.66666667, 0.67708333, 0.67708333,\n",
       "        0.66666667, 0.6875    , 0.65625   , 0.64583333, 0.69791667,\n",
       "        0.63541667, 0.72916667, 0.6875    , 0.66666667, 0.64583333,\n",
       "        0.71875   , 0.625     , 0.63541667, 0.71875   , 0.66666667,\n",
       "        0.71875   , 0.69791667, 0.6875    , 0.64583333, 0.71875   ,\n",
       "        0.73958333, 0.71875   , 0.67708333, 0.70833333, 0.6875    ,\n",
       "        0.63541667, 0.69791667, 0.69791667, 0.66666667, 0.67708333,\n",
       "        0.63541667, 0.65625   , 0.69791667, 0.67708333, 0.69791667,\n",
       "        0.70833333, 0.75      , 0.67708333, 0.6875    , 0.67708333,\n",
       "        0.71875   , 0.6875    , 0.71875   , 0.70833333, 0.67708333,\n",
       "        0.69791667, 0.6875    , 0.66666667, 0.72916667, 0.72916667,\n",
       "        0.70833333, 0.66666667, 0.70833333, 0.6875    , 0.69791667,\n",
       "        0.66666667, 0.60416667, 0.61458333, 0.61458333, 0.58333333,\n",
       "        0.65625   , 0.70833333, 0.625     , 0.69791667, 0.65625   ,\n",
       "        0.63541667, 0.64583333, 0.63541667, 0.65625   , 0.64583333,\n",
       "        0.64583333, 0.66666667, 0.66666667, 0.63541667, 0.63541667,\n",
       "        0.6875    , 0.64583333, 0.67708333, 0.63541667, 0.65625   ,\n",
       "        0.70833333, 0.64583333, 0.64583333, 0.64583333, 0.66666667,\n",
       "        0.65625   , 0.69791667, 0.64583333, 0.65625   , 0.6875    ,\n",
       "        0.66666667, 0.63541667, 0.72916667, 0.65625   , 0.67708333,\n",
       "        0.75      , 0.65625   , 0.67708333, 0.66666667, 0.65625   ,\n",
       "        0.6875    , 0.65625   , 0.66666667, 0.6875    , 0.63541667,\n",
       "        0.64583333, 0.65625   , 0.64583333, 0.64583333, 0.67708333,\n",
       "        0.69791667, 0.66666667, 0.72916667, 0.6875    , 0.67708333,\n",
       "        0.64583333, 0.70833333, 0.71875   , 0.66666667, 0.65625   ,\n",
       "        0.71875   , 0.6875    , 0.69791667, 0.67708333, 0.63541667,\n",
       "        0.66666667, 0.67708333, 0.70833333, 0.66666667, 0.6875    ,\n",
       "        0.64583333, 0.65625   , 0.64583333, 0.66666667, 0.66666667,\n",
       "        0.65625   , 0.66666667, 0.63541667, 0.625     , 0.625     ,\n",
       "        0.58333333, 0.63541667, 0.63541667, 0.63541667, 0.59375   ,\n",
       "        0.64583333, 0.67708333, 0.67708333, 0.64583333, 0.67708333,\n",
       "        0.63541667, 0.61458333, 0.66666667, 0.65625   , 0.65625   ,\n",
       "        0.57291667, 0.65625   , 0.6875    , 0.66666667, 0.67708333,\n",
       "        0.70833333, 0.67708333, 0.66666667, 0.66666667, 0.64583333,\n",
       "        0.6875    , 0.72916667, 0.71875   , 0.65625   , 0.64583333,\n",
       "        0.64583333, 0.69791667, 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.69791667, 0.71875   , 0.66666667, 0.71875   , 0.66666667,\n",
       "        0.71875   , 0.66666667, 0.67708333, 0.66666667, 0.64583333,\n",
       "        0.67708333, 0.71875   , 0.6875    , 0.65625   , 0.66666667,\n",
       "        0.76041667, 0.70833333, 0.64583333, 0.65625   , 0.63541667,\n",
       "        0.67708333, 0.70833333, 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.71875   , 0.73958333, 0.67708333, 0.6875    , 0.67708333,\n",
       "        0.70833333, 0.69791667, 0.70833333, 0.6875    , 0.67708333,\n",
       "        0.67708333, 0.67708333, 0.6875    , 0.65625   , 0.69791667,\n",
       "        0.63541667, 0.59375   , 0.65625   , 0.60416667, 0.625     ,\n",
       "        0.625     , 0.66666667, 0.64583333, 0.65625   , 0.64583333,\n",
       "        0.58333333, 0.625     , 0.6875    , 0.64583333, 0.65625   ,\n",
       "        0.625     , 0.6875    , 0.6875    , 0.69791667, 0.63541667,\n",
       "        0.64583333, 0.64583333, 0.64583333, 0.65625   , 0.67708333,\n",
       "        0.67708333, 0.71875   , 0.65625   , 0.64583333, 0.66666667,\n",
       "        0.67708333, 0.625     , 0.65625   , 0.67708333, 0.65625   ,\n",
       "        0.71875   , 0.625     , 0.67708333, 0.66666667, 0.66666667,\n",
       "        0.6875    , 0.625     , 0.6875    , 0.65625   , 0.65625   ,\n",
       "        0.66666667, 0.65625   , 0.66666667, 0.67708333, 0.70833333,\n",
       "        0.69791667, 0.64583333, 0.67708333, 0.66666667, 0.67708333,\n",
       "        0.73958333, 0.71875   , 0.63541667, 0.66666667, 0.6875    ,\n",
       "        0.65625   , 0.71875   , 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.63541667, 0.63541667, 0.6875    , 0.66666667, 0.69791667,\n",
       "        0.65625   , 0.6875    , 0.69791667, 0.66666667, 0.69791667,\n",
       "        0.75      , 0.69791667, 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.66666667, 0.55208333, 0.64583333, 0.625     , 0.625     ,\n",
       "        0.63541667, 0.64583333, 0.65625   , 0.63541667, 0.64583333,\n",
       "        0.63541667, 0.6875    , 0.63541667, 0.625     , 0.61458333,\n",
       "        0.6875    , 0.66666667, 0.65625   , 0.65625   , 0.66666667,\n",
       "        0.64583333, 0.66666667, 0.66666667, 0.63541667, 0.69791667,\n",
       "        0.71875   , 0.64583333, 0.64583333, 0.6875    , 0.67708333,\n",
       "        0.66666667, 0.70833333, 0.66666667, 0.64583333, 0.66666667,\n",
       "        0.61458333, 0.65625   , 0.66666667, 0.70833333, 0.65625   ,\n",
       "        0.70833333, 0.625     , 0.66666667, 0.6875    , 0.66666667,\n",
       "        0.60416667, 0.65625   , 0.63541667, 0.66666667, 0.70833333,\n",
       "        0.66666667, 0.66666667, 0.65625   , 0.6875    , 0.66666667,\n",
       "        0.71875   , 0.63541667, 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.67708333, 0.65625   , 0.6875    , 0.6875    , 0.65625   ,\n",
       "        0.67708333, 0.71875   , 0.66666667, 0.67708333, 0.67708333,\n",
       "        0.64583333, 0.70833333, 0.6875    , 0.70833333, 0.67708333,\n",
       "        0.72916667, 0.69791667, 0.65625   , 0.69791667, 0.65625   ]),\n",
       " 'split2_test_score': array([0.59375   , 0.67708333, 0.67708333, 0.69791667, 0.69791667,\n",
       "        0.59375   , 0.63541667, 0.66666667, 0.72916667, 0.66666667,\n",
       "        0.61458333, 0.67708333, 0.71875   , 0.64583333, 0.69791667,\n",
       "        0.63541667, 0.63541667, 0.65625   , 0.65625   , 0.71875   ,\n",
       "        0.73958333, 0.67708333, 0.72916667, 0.66666667, 0.70833333,\n",
       "        0.65625   , 0.64583333, 0.69791667, 0.73958333, 0.73958333,\n",
       "        0.71875   , 0.69791667, 0.66666667, 0.67708333, 0.70833333,\n",
       "        0.66666667, 0.64583333, 0.66666667, 0.67708333, 0.69791667,\n",
       "        0.65625   , 0.65625   , 0.67708333, 0.65625   , 0.6875    ,\n",
       "        0.67708333, 0.66666667, 0.71875   , 0.65625   , 0.65625   ,\n",
       "        0.58333333, 0.67708333, 0.67708333, 0.69791667, 0.66666667,\n",
       "        0.73958333, 0.64583333, 0.65625   , 0.69791667, 0.69791667,\n",
       "        0.66666667, 0.61458333, 0.69791667, 0.6875    , 0.63541667,\n",
       "        0.63541667, 0.69791667, 0.6875    , 0.69791667, 0.6875    ,\n",
       "        0.6875    , 0.67708333, 0.6875    , 0.67708333, 0.64583333,\n",
       "        0.61458333, 0.6875    , 0.69791667, 0.69791667, 0.6875    ,\n",
       "        0.625     , 0.61458333, 0.64583333, 0.72916667, 0.67708333,\n",
       "        0.6875    , 0.64583333, 0.64583333, 0.70833333, 0.69791667,\n",
       "        0.6875    , 0.625     , 0.6875    , 0.6875    , 0.64583333,\n",
       "        0.70833333, 0.66666667, 0.64583333, 0.70833333, 0.70833333,\n",
       "        0.76041667, 0.71875   , 0.71875   , 0.6875    , 0.6875    ,\n",
       "        0.61458333, 0.73958333, 0.66666667, 0.69791667, 0.69791667,\n",
       "        0.66666667, 0.64583333, 0.75      , 0.64583333, 0.6875    ,\n",
       "        0.66666667, 0.67708333, 0.72916667, 0.70833333, 0.70833333,\n",
       "        0.61458333, 0.6875    , 0.67708333, 0.6875    , 0.70833333,\n",
       "        0.6875    , 0.65625   , 0.6875    , 0.70833333, 0.67708333,\n",
       "        0.63541667, 0.6875    , 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.72916667, 0.70833333, 0.65625   , 0.70833333, 0.69791667,\n",
       "        0.67708333, 0.625     , 0.64583333, 0.67708333, 0.66666667,\n",
       "        0.64583333, 0.75      , 0.66666667, 0.67708333, 0.6875    ,\n",
       "        0.65625   , 0.6875    , 0.64583333, 0.6875    , 0.69791667,\n",
       "        0.64583333, 0.64583333, 0.70833333, 0.69791667, 0.65625   ,\n",
       "        0.61458333, 0.67708333, 0.6875    , 0.72916667, 0.69791667,\n",
       "        0.60416667, 0.66666667, 0.65625   , 0.71875   , 0.71875   ,\n",
       "        0.61458333, 0.72916667, 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.65625   , 0.66666667, 0.73958333, 0.73958333, 0.67708333,\n",
       "        0.66666667, 0.6875    , 0.71875   , 0.70833333, 0.67708333,\n",
       "        0.6875    , 0.6875    , 0.67708333, 0.65625   , 0.71875   ,\n",
       "        0.63541667, 0.63541667, 0.70833333, 0.66666667, 0.69791667,\n",
       "        0.61458333, 0.70833333, 0.69791667, 0.66666667, 0.69791667,\n",
       "        0.70833333, 0.66666667, 0.73958333, 0.71875   , 0.69791667,\n",
       "        0.6875    , 0.65625   , 0.67708333, 0.70833333, 0.71875   ,\n",
       "        0.64583333, 0.59375   , 0.67708333, 0.70833333, 0.69791667,\n",
       "        0.59375   , 0.66666667, 0.6875    , 0.69791667, 0.69791667,\n",
       "        0.66666667, 0.73958333, 0.70833333, 0.71875   , 0.6875    ,\n",
       "        0.5625    , 0.64583333, 0.65625   , 0.65625   , 0.70833333,\n",
       "        0.63541667, 0.66666667, 0.69791667, 0.64583333, 0.71875   ,\n",
       "        0.54166667, 0.63541667, 0.67708333, 0.66666667, 0.70833333,\n",
       "        0.625     , 0.66666667, 0.66666667, 0.70833333, 0.6875    ,\n",
       "        0.64583333, 0.64583333, 0.69791667, 0.69791667, 0.69791667,\n",
       "        0.61458333, 0.66666667, 0.69791667, 0.65625   , 0.72916667,\n",
       "        0.65625   , 0.58333333, 0.63541667, 0.6875    , 0.6875    ,\n",
       "        0.55208333, 0.67708333, 0.65625   , 0.6875    , 0.69791667,\n",
       "        0.66666667, 0.69791667, 0.71875   , 0.6875    , 0.69791667,\n",
       "        0.67708333, 0.69791667, 0.6875    , 0.69791667, 0.67708333,\n",
       "        0.66666667, 0.72916667, 0.69791667, 0.63541667, 0.72916667,\n",
       "        0.66666667, 0.6875    , 0.6875    , 0.70833333, 0.70833333,\n",
       "        0.67708333, 0.63541667, 0.72916667, 0.66666667, 0.70833333,\n",
       "        0.59375   , 0.66666667, 0.66666667, 0.70833333, 0.71875   ,\n",
       "        0.66666667, 0.65625   , 0.66666667, 0.69791667, 0.6875    ,\n",
       "        0.71875   , 0.72916667, 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.66666667, 0.64583333, 0.67708333, 0.71875   , 0.69791667,\n",
       "        0.625     , 0.69791667, 0.64583333, 0.72916667, 0.70833333,\n",
       "        0.66666667, 0.64583333, 0.71875   , 0.70833333, 0.70833333,\n",
       "        0.67708333, 0.66666667, 0.70833333, 0.6875    , 0.70833333,\n",
       "        0.67708333, 0.65625   , 0.66666667, 0.67708333, 0.6875    ,\n",
       "        0.64583333, 0.63541667, 0.67708333, 0.67708333, 0.6875    ,\n",
       "        0.63541667, 0.6875    , 0.67708333, 0.70833333, 0.6875    ,\n",
       "        0.66666667, 0.66666667, 0.67708333, 0.65625   , 0.6875    ,\n",
       "        0.65625   , 0.67708333, 0.70833333, 0.66666667, 0.6875    ,\n",
       "        0.6875    , 0.65625   , 0.70833333, 0.67708333, 0.6875    ,\n",
       "        0.64583333, 0.6875    , 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.63541667, 0.6875    , 0.6875    , 0.67708333, 0.69791667,\n",
       "        0.65625   , 0.64583333, 0.625     , 0.6875    , 0.66666667,\n",
       "        0.66666667, 0.64583333, 0.6875    , 0.69791667, 0.67708333,\n",
       "        0.65625   , 0.64583333, 0.66666667, 0.70833333, 0.66666667,\n",
       "        0.75      , 0.63541667, 0.70833333, 0.6875    , 0.67708333,\n",
       "        0.61458333, 0.65625   , 0.66666667, 0.67708333, 0.6875    ,\n",
       "        0.6875    , 0.64583333, 0.69791667, 0.6875    , 0.66666667,\n",
       "        0.59375   , 0.63541667, 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.60416667, 0.69791667, 0.6875    , 0.65625   , 0.6875    ,\n",
       "        0.63541667, 0.67708333, 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.70833333, 0.66666667, 0.625     , 0.70833333, 0.65625   ,\n",
       "        0.63541667, 0.6875    , 0.65625   , 0.6875    , 0.6875    ,\n",
       "        0.63541667, 0.6875    , 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.57291667, 0.63541667, 0.70833333, 0.67708333, 0.67708333,\n",
       "        0.6875    , 0.67708333, 0.6875    , 0.72916667, 0.6875    ,\n",
       "        0.65625   , 0.72916667, 0.64583333, 0.6875    , 0.69791667,\n",
       "        0.65625   , 0.66666667, 0.65625   , 0.6875    , 0.66666667,\n",
       "        0.54166667, 0.65625   , 0.67708333, 0.67708333, 0.6875    ,\n",
       "        0.57291667, 0.67708333, 0.69791667, 0.65625   , 0.64583333,\n",
       "        0.67708333, 0.64583333, 0.67708333, 0.625     , 0.6875    ,\n",
       "        0.72916667, 0.6875    , 0.67708333, 0.69791667, 0.67708333,\n",
       "        0.65625   , 0.6875    , 0.67708333, 0.66666667, 0.69791667,\n",
       "        0.65625   , 0.6875    , 0.70833333, 0.67708333, 0.67708333,\n",
       "        0.625     , 0.66666667, 0.6875    , 0.69791667, 0.69791667,\n",
       "        0.63541667, 0.63541667, 0.65625   , 0.67708333, 0.69791667,\n",
       "        0.625     , 0.66666667, 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.67708333, 0.59375   , 0.71875   , 0.67708333, 0.6875    ,\n",
       "        0.66666667, 0.64583333, 0.63541667, 0.65625   , 0.65625   ,\n",
       "        0.71875   , 0.64583333, 0.63541667, 0.70833333, 0.69791667,\n",
       "        0.64583333, 0.6875    , 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.66666667, 0.70833333, 0.6875    , 0.6875    , 0.70833333,\n",
       "        0.67708333, 0.66666667, 0.65625   , 0.67708333, 0.66666667,\n",
       "        0.6875    , 0.64583333, 0.70833333, 0.67708333, 0.6875    ,\n",
       "        0.67708333, 0.625     , 0.66666667, 0.67708333, 0.6875    ,\n",
       "        0.64583333, 0.69791667, 0.71875   , 0.65625   , 0.70833333,\n",
       "        0.70833333, 0.66666667, 0.6875    , 0.65625   , 0.6875    ,\n",
       "        0.72916667, 0.65625   , 0.64583333, 0.6875    , 0.6875    ,\n",
       "        0.63541667, 0.67708333, 0.67708333, 0.65625   , 0.6875    ,\n",
       "        0.71875   , 0.70833333, 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.66666667, 0.64583333, 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.61458333, 0.65625   , 0.65625   , 0.73958333, 0.72916667,\n",
       "        0.58333333, 0.60416667, 0.63541667, 0.69791667, 0.69791667,\n",
       "        0.63541667, 0.63541667, 0.65625   , 0.70833333, 0.69791667,\n",
       "        0.66666667, 0.69791667, 0.70833333, 0.66666667, 0.66666667,\n",
       "        0.69791667, 0.72916667, 0.70833333, 0.71875   , 0.70833333,\n",
       "        0.625     , 0.66666667, 0.67708333, 0.6875    , 0.67708333,\n",
       "        0.6875    , 0.70833333, 0.63541667, 0.69791667, 0.69791667,\n",
       "        0.65625   , 0.66666667, 0.70833333, 0.67708333, 0.67708333,\n",
       "        0.67708333, 0.625     , 0.69791667, 0.66666667, 0.69791667,\n",
       "        0.69791667, 0.71875   , 0.6875    , 0.69791667, 0.66666667,\n",
       "        0.69791667, 0.61458333, 0.66666667, 0.6875    , 0.64583333,\n",
       "        0.60416667, 0.67708333, 0.69791667, 0.67708333, 0.6875    ,\n",
       "        0.65625   , 0.63541667, 0.65625   , 0.65625   , 0.6875    ,\n",
       "        0.67708333, 0.63541667, 0.63541667, 0.6875    , 0.69791667,\n",
       "        0.6875    , 0.64583333, 0.66666667, 0.69791667, 0.6875    ,\n",
       "        0.65625   , 0.6875    , 0.72916667, 0.67708333, 0.6875    ]),\n",
       " 'split3_test_score': array([0.67708333, 0.75      , 0.76041667, 0.75      , 0.73958333,\n",
       "        0.71875   , 0.71875   , 0.73958333, 0.77083333, 0.72916667,\n",
       "        0.77083333, 0.75      , 0.77083333, 0.77083333, 0.8125    ,\n",
       "        0.76041667, 0.75      , 0.76041667, 0.79166667, 0.78125   ,\n",
       "        0.64583333, 0.70833333, 0.6875    , 0.77083333, 0.75      ,\n",
       "        0.75      , 0.75      , 0.75      , 0.73958333, 0.75      ,\n",
       "        0.69791667, 0.70833333, 0.71875   , 0.77083333, 0.72916667,\n",
       "        0.67708333, 0.71875   , 0.78125   , 0.77083333, 0.77083333,\n",
       "        0.76041667, 0.73958333, 0.69791667, 0.73958333, 0.78125   ,\n",
       "        0.66666667, 0.70833333, 0.69791667, 0.77083333, 0.75      ,\n",
       "        0.77083333, 0.75      , 0.79166667, 0.76041667, 0.73958333,\n",
       "        0.71875   , 0.75      , 0.75      , 0.73958333, 0.72916667,\n",
       "        0.70833333, 0.71875   , 0.6875    , 0.72916667, 0.78125   ,\n",
       "        0.71875   , 0.72916667, 0.66666667, 0.77083333, 0.73958333,\n",
       "        0.69791667, 0.73958333, 0.75      , 0.77083333, 0.73958333,\n",
       "        0.69791667, 0.66666667, 0.75      , 0.79166667, 0.77083333,\n",
       "        0.70833333, 0.73958333, 0.72916667, 0.77083333, 0.73958333,\n",
       "        0.71875   , 0.75      , 0.76041667, 0.72916667, 0.73958333,\n",
       "        0.71875   , 0.76041667, 0.73958333, 0.75      , 0.77083333,\n",
       "        0.71875   , 0.73958333, 0.71875   , 0.77083333, 0.79166667,\n",
       "        0.77083333, 0.72916667, 0.69791667, 0.75      , 0.77083333,\n",
       "        0.71875   , 0.75      , 0.78125   , 0.75      , 0.78125   ,\n",
       "        0.69791667, 0.70833333, 0.73958333, 0.77083333, 0.79166667,\n",
       "        0.70833333, 0.75      , 0.77083333, 0.80208333, 0.73958333,\n",
       "        0.73958333, 0.72916667, 0.70833333, 0.72916667, 0.73958333,\n",
       "        0.69791667, 0.73958333, 0.71875   , 0.76041667, 0.76041667,\n",
       "        0.72916667, 0.77083333, 0.72916667, 0.73958333, 0.75      ,\n",
       "        0.77083333, 0.75      , 0.8125    , 0.76041667, 0.73958333,\n",
       "        0.69791667, 0.75      , 0.79166667, 0.72916667, 0.75      ,\n",
       "        0.70833333, 0.77083333, 0.75      , 0.73958333, 0.70833333,\n",
       "        0.72916667, 0.82291667, 0.72916667, 0.70833333, 0.73958333,\n",
       "        0.72916667, 0.79166667, 0.6875    , 0.72916667, 0.71875   ,\n",
       "        0.72916667, 0.69791667, 0.71875   , 0.75      , 0.73958333,\n",
       "        0.66666667, 0.77083333, 0.72916667, 0.76041667, 0.75      ,\n",
       "        0.73958333, 0.75      , 0.79166667, 0.72916667, 0.77083333,\n",
       "        0.70833333, 0.77083333, 0.71875   , 0.77083333, 0.75      ,\n",
       "        0.66666667, 0.76041667, 0.72916667, 0.75      , 0.80208333,\n",
       "        0.6875    , 0.80208333, 0.77083333, 0.73958333, 0.78125   ,\n",
       "        0.6875    , 0.73958333, 0.77083333, 0.76041667, 0.8125    ,\n",
       "        0.70833333, 0.79166667, 0.79166667, 0.72916667, 0.73958333,\n",
       "        0.76041667, 0.72916667, 0.70833333, 0.78125   , 0.76041667,\n",
       "        0.6875    , 0.79166667, 0.73958333, 0.76041667, 0.73958333,\n",
       "        0.78125   , 0.64583333, 0.71875   , 0.78125   , 0.77083333,\n",
       "        0.69791667, 0.69791667, 0.72916667, 0.76041667, 0.75      ,\n",
       "        0.6875    , 0.73958333, 0.70833333, 0.78125   , 0.71875   ,\n",
       "        0.61458333, 0.77083333, 0.71875   , 0.76041667, 0.73958333,\n",
       "        0.78125   , 0.69791667, 0.77083333, 0.76041667, 0.75      ,\n",
       "        0.70833333, 0.77083333, 0.75      , 0.77083333, 0.75      ,\n",
       "        0.71875   , 0.65625   , 0.72916667, 0.78125   , 0.76041667,\n",
       "        0.67708333, 0.71875   , 0.6875    , 0.72916667, 0.76041667,\n",
       "        0.64583333, 0.75      , 0.70833333, 0.75      , 0.80208333,\n",
       "        0.75      , 0.76041667, 0.72916667, 0.78125   , 0.75      ,\n",
       "        0.73958333, 0.65625   , 0.78125   , 0.77083333, 0.76041667,\n",
       "        0.71875   , 0.75      , 0.76041667, 0.75      , 0.77083333,\n",
       "        0.71875   , 0.70833333, 0.72916667, 0.75      , 0.80208333,\n",
       "        0.69791667, 0.77083333, 0.75      , 0.73958333, 0.77083333,\n",
       "        0.72916667, 0.78125   , 0.69791667, 0.78125   , 0.75      ,\n",
       "        0.70833333, 0.75      , 0.70833333, 0.69791667, 0.76041667,\n",
       "        0.73958333, 0.69791667, 0.76041667, 0.77083333, 0.75      ,\n",
       "        0.67708333, 0.72916667, 0.71875   , 0.71875   , 0.77083333,\n",
       "        0.73958333, 0.67708333, 0.72916667, 0.72916667, 0.75      ,\n",
       "        0.75      , 0.80208333, 0.77083333, 0.77083333, 0.76041667,\n",
       "        0.75      , 0.71875   , 0.66666667, 0.73958333, 0.75      ,\n",
       "        0.72916667, 0.72916667, 0.75      , 0.72916667, 0.77083333,\n",
       "        0.73958333, 0.72916667, 0.76041667, 0.78125   , 0.72916667,\n",
       "        0.70833333, 0.6875    , 0.8125    , 0.78125   , 0.75      ,\n",
       "        0.71875   , 0.70833333, 0.79166667, 0.71875   , 0.77083333,\n",
       "        0.77083333, 0.77083333, 0.71875   , 0.75      , 0.79166667,\n",
       "        0.67708333, 0.67708333, 0.75      , 0.80208333, 0.80208333,\n",
       "        0.75      , 0.76041667, 0.72916667, 0.77083333, 0.77083333,\n",
       "        0.66666667, 0.73958333, 0.76041667, 0.73958333, 0.79166667,\n",
       "        0.73958333, 0.75      , 0.70833333, 0.72916667, 0.77083333,\n",
       "        0.71875   , 0.69791667, 0.77083333, 0.79166667, 0.75      ,\n",
       "        0.59375   , 0.72916667, 0.77083333, 0.75      , 0.71875   ,\n",
       "        0.70833333, 0.66666667, 0.8125    , 0.72916667, 0.73958333,\n",
       "        0.75      , 0.75      , 0.79166667, 0.70833333, 0.76041667,\n",
       "        0.73958333, 0.72916667, 0.75      , 0.72916667, 0.72916667,\n",
       "        0.77083333, 0.75      , 0.75      , 0.75      , 0.77083333,\n",
       "        0.71875   , 0.75      , 0.71875   , 0.70833333, 0.75      ,\n",
       "        0.6875    , 0.70833333, 0.75      , 0.76041667, 0.75      ,\n",
       "        0.76041667, 0.69791667, 0.76041667, 0.78125   , 0.76041667,\n",
       "        0.80208333, 0.69791667, 0.76041667, 0.76041667, 0.75      ,\n",
       "        0.70833333, 0.71875   , 0.73958333, 0.77083333, 0.75      ,\n",
       "        0.72916667, 0.71875   , 0.78125   , 0.73958333, 0.79166667,\n",
       "        0.76041667, 0.70833333, 0.72916667, 0.73958333, 0.76041667,\n",
       "        0.67708333, 0.72916667, 0.73958333, 0.77083333, 0.78125   ,\n",
       "        0.72916667, 0.70833333, 0.79166667, 0.78125   , 0.78125   ,\n",
       "        0.69791667, 0.79166667, 0.78125   , 0.75      , 0.75      ,\n",
       "        0.76041667, 0.6875    , 0.77083333, 0.72916667, 0.76041667,\n",
       "        0.76041667, 0.78125   , 0.76041667, 0.75      , 0.70833333,\n",
       "        0.71875   , 0.79166667, 0.75      , 0.76041667, 0.76041667,\n",
       "        0.6875    , 0.79166667, 0.72916667, 0.70833333, 0.77083333,\n",
       "        0.71875   , 0.72916667, 0.77083333, 0.76041667, 0.75      ,\n",
       "        0.75      , 0.8125    , 0.76041667, 0.72916667, 0.76041667,\n",
       "        0.79166667, 0.76041667, 0.71875   , 0.76041667, 0.73958333,\n",
       "        0.76041667, 0.76041667, 0.75      , 0.73958333, 0.73958333,\n",
       "        0.67708333, 0.71875   , 0.71875   , 0.73958333, 0.75      ,\n",
       "        0.61458333, 0.70833333, 0.75      , 0.71875   , 0.72916667,\n",
       "        0.71875   , 0.76041667, 0.72916667, 0.76041667, 0.76041667,\n",
       "        0.72916667, 0.75      , 0.78125   , 0.73958333, 0.79166667,\n",
       "        0.69791667, 0.67708333, 0.73958333, 0.75      , 0.80208333,\n",
       "        0.66666667, 0.79166667, 0.77083333, 0.78125   , 0.75      ,\n",
       "        0.70833333, 0.76041667, 0.78125   , 0.79166667, 0.78125   ,\n",
       "        0.69791667, 0.75      , 0.77083333, 0.76041667, 0.73958333,\n",
       "        0.625     , 0.8125    , 0.73958333, 0.73958333, 0.73958333,\n",
       "        0.75      , 0.77083333, 0.75      , 0.77083333, 0.75      ,\n",
       "        0.72916667, 0.70833333, 0.79166667, 0.80208333, 0.73958333,\n",
       "        0.66666667, 0.75      , 0.70833333, 0.76041667, 0.76041667,\n",
       "        0.78125   , 0.76041667, 0.69791667, 0.77083333, 0.73958333,\n",
       "        0.72916667, 0.77083333, 0.72916667, 0.75      , 0.72916667,\n",
       "        0.76041667, 0.73958333, 0.72916667, 0.75      , 0.73958333,\n",
       "        0.77083333, 0.75      , 0.71875   , 0.76041667, 0.75      ,\n",
       "        0.75      , 0.72916667, 0.75      , 0.70833333, 0.75      ,\n",
       "        0.63541667, 0.76041667, 0.73958333, 0.75      , 0.71875   ,\n",
       "        0.72916667, 0.82291667, 0.72916667, 0.69791667, 0.76041667,\n",
       "        0.66666667, 0.75      , 0.72916667, 0.76041667, 0.75      ,\n",
       "        0.67708333, 0.78125   , 0.73958333, 0.77083333, 0.75      ,\n",
       "        0.72916667, 0.72916667, 0.72916667, 0.75      , 0.77083333,\n",
       "        0.78125   , 0.76041667, 0.69791667, 0.77083333, 0.78125   ,\n",
       "        0.77083333, 0.73958333, 0.76041667, 0.79166667, 0.79166667,\n",
       "        0.75      , 0.8125    , 0.75      , 0.72916667, 0.73958333,\n",
       "        0.64583333, 0.73958333, 0.76041667, 0.73958333, 0.73958333,\n",
       "        0.73958333, 0.73958333, 0.77083333, 0.75      , 0.75      ,\n",
       "        0.72916667, 0.75      , 0.71875   , 0.73958333, 0.71875   ,\n",
       "        0.70833333, 0.69791667, 0.77083333, 0.78125   , 0.75      ,\n",
       "        0.69791667, 0.79166667, 0.77083333, 0.71875   , 0.76041667,\n",
       "        0.77083333, 0.78125   , 0.75      , 0.70833333, 0.72916667,\n",
       "        0.75      , 0.71875   , 0.76041667, 0.75      , 0.73958333]),\n",
       " 'split4_test_score': array([0.63541667, 0.72916667, 0.72916667, 0.72916667, 0.6875    ,\n",
       "        0.66666667, 0.70833333, 0.72916667, 0.71875   , 0.70833333,\n",
       "        0.72916667, 0.70833333, 0.73958333, 0.70833333, 0.69791667,\n",
       "        0.6875    , 0.69791667, 0.72916667, 0.67708333, 0.70833333,\n",
       "        0.78125   , 0.70833333, 0.73958333, 0.69791667, 0.69791667,\n",
       "        0.6875    , 0.71875   , 0.71875   , 0.71875   , 0.69791667,\n",
       "        0.76041667, 0.73958333, 0.71875   , 0.75      , 0.70833333,\n",
       "        0.8125    , 0.6875    , 0.70833333, 0.70833333, 0.72916667,\n",
       "        0.73958333, 0.72916667, 0.71875   , 0.76041667, 0.70833333,\n",
       "        0.66666667, 0.73958333, 0.72916667, 0.72916667, 0.69791667,\n",
       "        0.73958333, 0.71875   , 0.65625   , 0.71875   , 0.69791667,\n",
       "        0.72916667, 0.67708333, 0.67708333, 0.71875   , 0.66666667,\n",
       "        0.66666667, 0.76041667, 0.65625   , 0.71875   , 0.66666667,\n",
       "        0.65625   , 0.72916667, 0.63541667, 0.69791667, 0.72916667,\n",
       "        0.75      , 0.57291667, 0.72916667, 0.73958333, 0.69791667,\n",
       "        0.72916667, 0.75      , 0.65625   , 0.70833333, 0.6875    ,\n",
       "        0.61458333, 0.66666667, 0.69791667, 0.70833333, 0.71875   ,\n",
       "        0.64583333, 0.69791667, 0.72916667, 0.67708333, 0.69791667,\n",
       "        0.70833333, 0.69791667, 0.72916667, 0.66666667, 0.67708333,\n",
       "        0.6875    , 0.67708333, 0.72916667, 0.67708333, 0.6875    ,\n",
       "        0.72916667, 0.76041667, 0.75      , 0.73958333, 0.71875   ,\n",
       "        0.64583333, 0.71875   , 0.70833333, 0.69791667, 0.70833333,\n",
       "        0.69791667, 0.77083333, 0.6875    , 0.72916667, 0.71875   ,\n",
       "        0.71875   , 0.66666667, 0.65625   , 0.70833333, 0.69791667,\n",
       "        0.625     , 0.76041667, 0.76041667, 0.72916667, 0.70833333,\n",
       "        0.55208333, 0.65625   , 0.73958333, 0.71875   , 0.70833333,\n",
       "        0.63541667, 0.73958333, 0.77083333, 0.70833333, 0.70833333,\n",
       "        0.6875    , 0.69791667, 0.73958333, 0.71875   , 0.6875    ,\n",
       "        0.5625    , 0.78125   , 0.73958333, 0.6875    , 0.70833333,\n",
       "        0.61458333, 0.67708333, 0.75      , 0.73958333, 0.69791667,\n",
       "        0.77083333, 0.64583333, 0.78125   , 0.70833333, 0.63541667,\n",
       "        0.77083333, 0.65625   , 0.69791667, 0.67708333, 0.6875    ,\n",
       "        0.61458333, 0.625     , 0.69791667, 0.6875    , 0.71875   ,\n",
       "        0.66666667, 0.63541667, 0.69791667, 0.70833333, 0.6875    ,\n",
       "        0.69791667, 0.71875   , 0.72916667, 0.67708333, 0.6875    ,\n",
       "        0.61458333, 0.72916667, 0.69791667, 0.67708333, 0.70833333,\n",
       "        0.6875    , 0.63541667, 0.73958333, 0.67708333, 0.71875   ,\n",
       "        0.72916667, 0.73958333, 0.73958333, 0.72916667, 0.71875   ,\n",
       "        0.71875   , 0.71875   , 0.6875    , 0.71875   , 0.71875   ,\n",
       "        0.63541667, 0.73958333, 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.63541667, 0.72916667, 0.64583333, 0.70833333, 0.70833333,\n",
       "        0.64583333, 0.69791667, 0.70833333, 0.75      , 0.70833333,\n",
       "        0.57291667, 0.72916667, 0.70833333, 0.73958333, 0.70833333,\n",
       "        0.60416667, 0.6875    , 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.6875    , 0.69791667, 0.78125   , 0.73958333, 0.70833333,\n",
       "        0.69791667, 0.6875    , 0.6875    , 0.70833333, 0.73958333,\n",
       "        0.70833333, 0.61458333, 0.70833333, 0.65625   , 0.67708333,\n",
       "        0.65625   , 0.625     , 0.71875   , 0.69791667, 0.67708333,\n",
       "        0.65625   , 0.6875    , 0.70833333, 0.6875    , 0.70833333,\n",
       "        0.71875   , 0.63541667, 0.75      , 0.71875   , 0.70833333,\n",
       "        0.65625   , 0.6875    , 0.70833333, 0.70833333, 0.70833333,\n",
       "        0.71875   , 0.65625   , 0.65625   , 0.71875   , 0.70833333,\n",
       "        0.66666667, 0.71875   , 0.69791667, 0.71875   , 0.69791667,\n",
       "        0.77083333, 0.6875    , 0.72916667, 0.70833333, 0.69791667,\n",
       "        0.6875    , 0.67708333, 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.70833333, 0.72916667, 0.6875    , 0.70833333, 0.70833333,\n",
       "        0.71875   , 0.67708333, 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.67708333, 0.70833333, 0.73958333, 0.70833333, 0.70833333,\n",
       "        0.69791667, 0.72916667, 0.70833333, 0.73958333, 0.72916667,\n",
       "        0.70833333, 0.65625   , 0.72916667, 0.73958333, 0.69791667,\n",
       "        0.65625   , 0.72916667, 0.64583333, 0.70833333, 0.70833333,\n",
       "        0.65625   , 0.64583333, 0.6875    , 0.71875   , 0.6875    ,\n",
       "        0.71875   , 0.6875    , 0.73958333, 0.69791667, 0.64583333,\n",
       "        0.58333333, 0.6875    , 0.625     , 0.69791667, 0.69791667,\n",
       "        0.69791667, 0.64583333, 0.64583333, 0.6875    , 0.67708333,\n",
       "        0.6875    , 0.70833333, 0.64583333, 0.71875   , 0.67708333,\n",
       "        0.66666667, 0.69791667, 0.72916667, 0.69791667, 0.70833333,\n",
       "        0.72916667, 0.6875    , 0.67708333, 0.67708333, 0.69791667,\n",
       "        0.64583333, 0.70833333, 0.65625   , 0.69791667, 0.72916667,\n",
       "        0.70833333, 0.71875   , 0.6875    , 0.70833333, 0.72916667,\n",
       "        0.72916667, 0.70833333, 0.70833333, 0.69791667, 0.72916667,\n",
       "        0.61458333, 0.75      , 0.71875   , 0.70833333, 0.71875   ,\n",
       "        0.67708333, 0.75      , 0.70833333, 0.73958333, 0.72916667,\n",
       "        0.66666667, 0.67708333, 0.70833333, 0.75      , 0.71875   ,\n",
       "        0.67708333, 0.625     , 0.71875   , 0.71875   , 0.72916667,\n",
       "        0.67708333, 0.65625   , 0.69791667, 0.69791667, 0.75      ,\n",
       "        0.58333333, 0.66666667, 0.77083333, 0.69791667, 0.75      ,\n",
       "        0.6875    , 0.60416667, 0.67708333, 0.69791667, 0.73958333,\n",
       "        0.71875   , 0.6875    , 0.64583333, 0.67708333, 0.70833333,\n",
       "        0.71875   , 0.69791667, 0.76041667, 0.64583333, 0.69791667,\n",
       "        0.66666667, 0.76041667, 0.67708333, 0.6875    , 0.71875   ,\n",
       "        0.75      , 0.64583333, 0.66666667, 0.69791667, 0.71875   ,\n",
       "        0.69791667, 0.66666667, 0.65625   , 0.70833333, 0.70833333,\n",
       "        0.75      , 0.69791667, 0.70833333, 0.70833333, 0.67708333,\n",
       "        0.71875   , 0.70833333, 0.6875    , 0.72916667, 0.72916667,\n",
       "        0.64583333, 0.6875    , 0.71875   , 0.71875   , 0.71875   ,\n",
       "        0.73958333, 0.71875   , 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.66666667, 0.73958333, 0.69791667, 0.70833333, 0.70833333,\n",
       "        0.60416667, 0.71875   , 0.71875   , 0.72916667, 0.71875   ,\n",
       "        0.73958333, 0.6875    , 0.6875    , 0.71875   , 0.72916667,\n",
       "        0.65625   , 0.75      , 0.64583333, 0.72916667, 0.70833333,\n",
       "        0.6875    , 0.73958333, 0.75      , 0.73958333, 0.71875   ,\n",
       "        0.69791667, 0.69791667, 0.75      , 0.72916667, 0.72916667,\n",
       "        0.64583333, 0.71875   , 0.67708333, 0.73958333, 0.69791667,\n",
       "        0.60416667, 0.6875    , 0.69791667, 0.64583333, 0.65625   ,\n",
       "        0.66666667, 0.78125   , 0.69791667, 0.71875   , 0.69791667,\n",
       "        0.66666667, 0.72916667, 0.69791667, 0.72916667, 0.70833333,\n",
       "        0.75      , 0.73958333, 0.75      , 0.71875   , 0.71875   ,\n",
       "        0.73958333, 0.69791667, 0.66666667, 0.72916667, 0.70833333,\n",
       "        0.70833333, 0.67708333, 0.69791667, 0.67708333, 0.70833333,\n",
       "        0.69791667, 0.70833333, 0.72916667, 0.70833333, 0.69791667,\n",
       "        0.69791667, 0.71875   , 0.71875   , 0.70833333, 0.71875   ,\n",
       "        0.72916667, 0.72916667, 0.70833333, 0.73958333, 0.70833333,\n",
       "        0.72916667, 0.73958333, 0.70833333, 0.73958333, 0.70833333,\n",
       "        0.75      , 0.70833333, 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.73958333, 0.71875   , 0.72916667, 0.71875   , 0.72916667,\n",
       "        0.69791667, 0.72916667, 0.73958333, 0.71875   , 0.72916667,\n",
       "        0.77083333, 0.65625   , 0.73958333, 0.72916667, 0.75      ,\n",
       "        0.70833333, 0.625     , 0.71875   , 0.80208333, 0.6875    ,\n",
       "        0.75      , 0.69791667, 0.72916667, 0.72916667, 0.6875    ,\n",
       "        0.66666667, 0.6875    , 0.73958333, 0.71875   , 0.6875    ,\n",
       "        0.72916667, 0.65625   , 0.71875   , 0.66666667, 0.70833333,\n",
       "        0.67708333, 0.73958333, 0.66666667, 0.69791667, 0.69791667,\n",
       "        0.65625   , 0.67708333, 0.69791667, 0.69791667, 0.71875   ,\n",
       "        0.69791667, 0.71875   , 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.67708333, 0.71875   , 0.72916667, 0.73958333, 0.66666667,\n",
       "        0.66666667, 0.75      , 0.71875   , 0.70833333, 0.72916667,\n",
       "        0.72916667, 0.73958333, 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.76041667, 0.71875   , 0.69791667, 0.72916667, 0.72916667,\n",
       "        0.6875    , 0.73958333, 0.71875   , 0.70833333, 0.71875   ,\n",
       "        0.69791667, 0.76041667, 0.71875   , 0.73958333, 0.72916667,\n",
       "        0.70833333, 0.73958333, 0.72916667, 0.72916667, 0.70833333,\n",
       "        0.61458333, 0.6875    , 0.70833333, 0.73958333, 0.71875   ,\n",
       "        0.78125   , 0.71875   , 0.72916667, 0.71875   , 0.71875   ,\n",
       "        0.70833333, 0.60416667, 0.65625   , 0.71875   , 0.72916667,\n",
       "        0.76041667, 0.76041667, 0.70833333, 0.73958333, 0.69791667,\n",
       "        0.72916667, 0.63541667, 0.72916667, 0.67708333, 0.70833333,\n",
       "        0.65625   , 0.625     , 0.78125   , 0.6875    , 0.69791667]),\n",
       " 'mean_test_score': array([0.65625   , 0.68125   , 0.6875    , 0.69166667, 0.67083333,\n",
       "        0.64583333, 0.65833333, 0.68958333, 0.69583333, 0.67708333,\n",
       "        0.69583333, 0.68541667, 0.69583333, 0.68125   , 0.69583333,\n",
       "        0.675     , 0.69166667, 0.68333333, 0.6875    , 0.69791667,\n",
       "        0.69583333, 0.67708333, 0.70416667, 0.67916667, 0.69166667,\n",
       "        0.68541667, 0.68958333, 0.68541667, 0.69791667, 0.7       ,\n",
       "        0.71458333, 0.6875    , 0.68125   , 0.69791667, 0.69375   ,\n",
       "        0.69166667, 0.68333333, 0.7       , 0.69583333, 0.70833333,\n",
       "        0.72291667, 0.68333333, 0.68125   , 0.70625   , 0.70625   ,\n",
       "        0.66041667, 0.69583333, 0.7       , 0.69583333, 0.68958333,\n",
       "        0.6625    , 0.70416667, 0.70208333, 0.70625   , 0.6875    ,\n",
       "        0.68541667, 0.66666667, 0.69375   , 0.68958333, 0.68333333,\n",
       "        0.68333333, 0.66666667, 0.67083333, 0.69791667, 0.67291667,\n",
       "        0.67708333, 0.70625   , 0.67083333, 0.69791667, 0.69583333,\n",
       "        0.69583333, 0.65833333, 0.68958333, 0.69583333, 0.68125   ,\n",
       "        0.68541667, 0.69583333, 0.69791667, 0.7       , 0.7       ,\n",
       "        0.63333333, 0.65833333, 0.6625    , 0.7       , 0.67708333,\n",
       "        0.675     , 0.68958333, 0.6875    , 0.67916667, 0.67916667,\n",
       "        0.68333333, 0.67291667, 0.69375   , 0.68541667, 0.675     ,\n",
       "        0.6875    , 0.6875    , 0.67083333, 0.68541667, 0.69375   ,\n",
       "        0.72083333, 0.71041667, 0.68958333, 0.69375   , 0.69583333,\n",
       "        0.6625    , 0.70208333, 0.70208333, 0.68333333, 0.7       ,\n",
       "        0.68333333, 0.66666667, 0.70416667, 0.69166667, 0.69791667,\n",
       "        0.7       , 0.675     , 0.7       , 0.70833333, 0.69375   ,\n",
       "        0.68125   , 0.72708333, 0.70208333, 0.69166667, 0.68541667,\n",
       "        0.6625    , 0.68541667, 0.68958333, 0.71041667, 0.69791667,\n",
       "        0.66666667, 0.70208333, 0.69791667, 0.7       , 0.7       ,\n",
       "        0.70625   , 0.70625   , 0.71041667, 0.69583333, 0.68958333,\n",
       "        0.63541667, 0.7       , 0.68541667, 0.68958333, 0.68541667,\n",
       "        0.65625   , 0.7125    , 0.71041667, 0.7       , 0.68125   ,\n",
       "        0.6875    , 0.70833333, 0.7       , 0.68125   , 0.68125   ,\n",
       "        0.68333333, 0.68333333, 0.68333333, 0.69375   , 0.68541667,\n",
       "        0.63541667, 0.63333333, 0.6625    , 0.68333333, 0.67916667,\n",
       "        0.6375    , 0.69166667, 0.66041667, 0.69583333, 0.6875    ,\n",
       "        0.66041667, 0.68958333, 0.70208333, 0.67291667, 0.68958333,\n",
       "        0.66041667, 0.69375   , 0.69791667, 0.69583333, 0.6875    ,\n",
       "        0.66458333, 0.6875    , 0.69166667, 0.69583333, 0.70833333,\n",
       "        0.67916667, 0.70416667, 0.70416667, 0.68333333, 0.71875   ,\n",
       "        0.66041667, 0.68125   , 0.68541667, 0.69375   , 0.70208333,\n",
       "        0.66875   , 0.71458333, 0.7125    , 0.69583333, 0.69166667,\n",
       "        0.70208333, 0.69583333, 0.6875    , 0.69583333, 0.70625   ,\n",
       "        0.65416667, 0.68333333, 0.6875    , 0.7125    , 0.68958333,\n",
       "        0.67083333, 0.67083333, 0.67916667, 0.71875   , 0.7       ,\n",
       "        0.65      , 0.67083333, 0.67916667, 0.69583333, 0.69166667,\n",
       "        0.67708333, 0.70208333, 0.7125    , 0.72083333, 0.68333333,\n",
       "        0.65208333, 0.6875    , 0.675     , 0.69791667, 0.69375   ,\n",
       "        0.68958333, 0.67916667, 0.71666667, 0.67291667, 0.68958333,\n",
       "        0.66041667, 0.67291667, 0.69791667, 0.69166667, 0.69791667,\n",
       "        0.64791667, 0.65625   , 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.66875   , 0.6625    , 0.67708333, 0.68333333, 0.68958333,\n",
       "        0.62916667, 0.68958333, 0.68125   , 0.68958333, 0.70833333,\n",
       "        0.68333333, 0.65208333, 0.67083333, 0.69583333, 0.69583333,\n",
       "        0.64375   , 0.68541667, 0.68541667, 0.70416667, 0.69375   ,\n",
       "        0.6875    , 0.7       , 0.70208333, 0.68541667, 0.70833333,\n",
       "        0.66041667, 0.68333333, 0.69166667, 0.69375   , 0.69375   ,\n",
       "        0.68541667, 0.7125    , 0.69375   , 0.68541667, 0.70625   ,\n",
       "        0.7       , 0.69583333, 0.68541667, 0.69583333, 0.7       ,\n",
       "        0.68541667, 0.6875    , 0.70208333, 0.68541667, 0.69583333,\n",
       "        0.65833333, 0.6875    , 0.69583333, 0.70625   , 0.70208333,\n",
       "        0.65625   , 0.66458333, 0.6875    , 0.69583333, 0.7       ,\n",
       "        0.67291667, 0.69583333, 0.67083333, 0.6875    , 0.6875    ,\n",
       "        0.69583333, 0.68958333, 0.7       , 0.71041667, 0.68541667,\n",
       "        0.69375   , 0.70208333, 0.66875   , 0.7125    , 0.68958333,\n",
       "        0.67291667, 0.67708333, 0.68333333, 0.68333333, 0.70208333,\n",
       "        0.68541667, 0.65833333, 0.66458333, 0.675     , 0.66458333,\n",
       "        0.66666667, 0.6875    , 0.67291667, 0.70625   , 0.68333333,\n",
       "        0.66666667, 0.66458333, 0.69375   , 0.6875    , 0.69583333,\n",
       "        0.68958333, 0.70625   , 0.68541667, 0.69375   , 0.69583333,\n",
       "        0.66458333, 0.67916667, 0.68333333, 0.6875    , 0.69791667,\n",
       "        0.69166667, 0.68958333, 0.68125   , 0.68958333, 0.69791667,\n",
       "        0.675     , 0.7       , 0.70625   , 0.68333333, 0.70625   ,\n",
       "        0.675     , 0.69791667, 0.70208333, 0.67708333, 0.69791667,\n",
       "        0.68958333, 0.69375   , 0.6875    , 0.70208333, 0.70208333,\n",
       "        0.65208333, 0.67291667, 0.67916667, 0.7       , 0.68125   ,\n",
       "        0.68541667, 0.65208333, 0.69583333, 0.6875    , 0.69166667,\n",
       "        0.70208333, 0.67291667, 0.70416667, 0.69375   , 0.7       ,\n",
       "        0.6875    , 0.6625    , 0.71666667, 0.68333333, 0.6875    ,\n",
       "        0.70625   , 0.66666667, 0.69583333, 0.6875    , 0.6875    ,\n",
       "        0.68125   , 0.68541667, 0.68541667, 0.675     , 0.68541667,\n",
       "        0.64791667, 0.68125   , 0.70416667, 0.68125   , 0.68541667,\n",
       "        0.66458333, 0.69166667, 0.68541667, 0.67708333, 0.68958333,\n",
       "        0.68541667, 0.64791667, 0.67708333, 0.68541667, 0.675     ,\n",
       "        0.67916667, 0.67291667, 0.67708333, 0.7       , 0.68541667,\n",
       "        0.67916667, 0.66875   , 0.69583333, 0.68333333, 0.7       ,\n",
       "        0.65625   , 0.68333333, 0.68333333, 0.69166667, 0.69583333,\n",
       "        0.63958333, 0.67291667, 0.69375   , 0.69375   , 0.69791667,\n",
       "        0.69791667, 0.69791667, 0.70833333, 0.70833333, 0.68958333,\n",
       "        0.64583333, 0.72708333, 0.69375   , 0.7       , 0.69583333,\n",
       "        0.67708333, 0.68958333, 0.69583333, 0.70208333, 0.67916667,\n",
       "        0.6625    , 0.7       , 0.68958333, 0.69375   , 0.67708333,\n",
       "        0.65625   , 0.71666667, 0.68541667, 0.68125   , 0.68541667,\n",
       "        0.70416667, 0.70416667, 0.69166667, 0.67291667, 0.68958333,\n",
       "        0.68541667, 0.69166667, 0.70416667, 0.7       , 0.69166667,\n",
       "        0.69375   , 0.72083333, 0.69166667, 0.69166667, 0.69166667,\n",
       "        0.675     , 0.68541667, 0.68958333, 0.68125   , 0.68333333,\n",
       "        0.68333333, 0.70833333, 0.69375   , 0.68958333, 0.69583333,\n",
       "        0.65416667, 0.67291667, 0.67708333, 0.68125   , 0.68333333,\n",
       "        0.64791667, 0.68958333, 0.70416667, 0.69791667, 0.68333333,\n",
       "        0.68125   , 0.66041667, 0.69166667, 0.68541667, 0.69166667,\n",
       "        0.67083333, 0.67916667, 0.68958333, 0.68958333, 0.68333333,\n",
       "        0.67916667, 0.66666667, 0.68333333, 0.69791667, 0.70625   ,\n",
       "        0.67291667, 0.71875   , 0.69375   , 0.7       , 0.68958333,\n",
       "        0.68333333, 0.69791667, 0.69583333, 0.71458333, 0.69583333,\n",
       "        0.70208333, 0.69166667, 0.70208333, 0.70208333, 0.68125   ,\n",
       "        0.68125   , 0.67708333, 0.69583333, 0.67916667, 0.68125   ,\n",
       "        0.69583333, 0.67291667, 0.69166667, 0.69166667, 0.70416667,\n",
       "        0.67083333, 0.68333333, 0.72083333, 0.69583333, 0.70208333,\n",
       "        0.70416667, 0.68958333, 0.67708333, 0.68541667, 0.7125    ,\n",
       "        0.7       , 0.69166667, 0.66458333, 0.71458333, 0.68333333,\n",
       "        0.68333333, 0.68125   , 0.69375   , 0.68958333, 0.6875    ,\n",
       "        0.68125   , 0.68541667, 0.69166667, 0.7       , 0.6875    ,\n",
       "        0.71875   , 0.68541667, 0.675     , 0.68125   , 0.68333333,\n",
       "        0.6625    , 0.67291667, 0.66666667, 0.68958333, 0.6875    ,\n",
       "        0.62291667, 0.66666667, 0.67291667, 0.68333333, 0.6875    ,\n",
       "        0.675     , 0.70416667, 0.6625    , 0.68333333, 0.68958333,\n",
       "        0.67291667, 0.69791667, 0.70208333, 0.69166667, 0.68125   ,\n",
       "        0.675     , 0.71875   , 0.69375   , 0.69791667, 0.70833333,\n",
       "        0.675     , 0.67708333, 0.67916667, 0.70208333, 0.70208333,\n",
       "        0.70416667, 0.7125    , 0.67291667, 0.70208333, 0.70208333,\n",
       "        0.68541667, 0.68958333, 0.70208333, 0.71041667, 0.70416667,\n",
       "        0.69583333, 0.68541667, 0.6875    , 0.69583333, 0.69375   ,\n",
       "        0.65625   , 0.6875    , 0.69166667, 0.69791667, 0.69583333,\n",
       "        0.68333333, 0.68333333, 0.68541667, 0.70416667, 0.675     ,\n",
       "        0.7       , 0.67291667, 0.6875    , 0.68958333, 0.69166667,\n",
       "        0.66458333, 0.63958333, 0.67708333, 0.69166667, 0.6875    ,\n",
       "        0.70625   , 0.72916667, 0.68541667, 0.69791667, 0.69583333,\n",
       "        0.68125   , 0.67916667, 0.6875    , 0.68958333, 0.69166667,\n",
       "        0.68333333, 0.67708333, 0.71875   , 0.69166667, 0.68125   ]),\n",
       " 'std_test_score': array([0.0389756 , 0.05535554, 0.05017331, 0.04497299, 0.04956407,\n",
       "        0.04320092, 0.04768968, 0.0375    , 0.05720638, 0.03608439,\n",
       "        0.05488308, 0.04439016, 0.06159061, 0.05253967, 0.06468406,\n",
       "        0.04677072, 0.03703414, 0.05335937, 0.05311479, 0.05551214,\n",
       "        0.06052433, 0.02795085, 0.02517301, 0.05327797, 0.03761556,\n",
       "        0.03632416, 0.03919768, 0.05077524, 0.04370037, 0.03974747,\n",
       "        0.02517301, 0.0389756 , 0.03267581, 0.05432669, 0.02763854,\n",
       "        0.07471009, 0.03761556, 0.04340139, 0.04135299, 0.03784563,\n",
       "        0.03761556, 0.04956407, 0.02763854, 0.04028975, 0.05120086,\n",
       "        0.01816208, 0.03047654, 0.025     , 0.05162297, 0.04439016,\n",
       "        0.07699883, 0.02763854, 0.05212498, 0.03186887, 0.04370037,\n",
       "        0.05488308, 0.05060399, 0.04299952, 0.05034602, 0.03523236,\n",
       "        0.02041241, 0.06319063, 0.03200477, 0.02946278, 0.05613414,\n",
       "        0.02946278, 0.02019867, 0.02990146, 0.0497389 , 0.03691676,\n",
       "        0.05720638, 0.05833333, 0.05034602, 0.05720638, 0.03761556,\n",
       "        0.03919768, 0.03864008, 0.03159531, 0.05644257, 0.04859127,\n",
       "        0.03919768, 0.04439016, 0.04497299, 0.05034602, 0.04750731,\n",
       "        0.02748105, 0.03510896, 0.04796194, 0.03572173, 0.04389856,\n",
       "        0.03644345, 0.05043216, 0.03761556, 0.03385016, 0.04991312,\n",
       "        0.03294039, 0.02946278, 0.04497299, 0.05077524, 0.0557462 ,\n",
       "        0.04238956, 0.03572173, 0.04439016, 0.04448783, 0.04535738,\n",
       "        0.04299952, 0.04299952, 0.04399732, 0.04399732, 0.04768968,\n",
       "        0.01412985, 0.06588078, 0.03397814, 0.05      , 0.05472469,\n",
       "        0.0344853 , 0.0463044 , 0.0463044 , 0.05145454, 0.02990146,\n",
       "        0.05212498, 0.02667968, 0.03131937, 0.041978  , 0.04677072,\n",
       "        0.06130808, 0.03118048, 0.0463044 , 0.03691676, 0.03423266,\n",
       "        0.03423266, 0.04592793, 0.04564355, 0.03691676, 0.04289846,\n",
       "        0.04487637, 0.02411633, 0.06568284, 0.04487637, 0.03320287,\n",
       "        0.05628857, 0.07138267, 0.08212668, 0.03320287, 0.04187448,\n",
       "        0.03090083, 0.04592793, 0.0375    , 0.03974747, 0.02517301,\n",
       "        0.05551214, 0.06002025, 0.04991312, 0.02763854, 0.04039733,\n",
       "        0.06865524, 0.06928454, 0.04093101, 0.03523236, 0.02585349,\n",
       "        0.05929271, 0.04768968, 0.04912428, 0.05170697, 0.05527708,\n",
       "        0.02825971, 0.04592793, 0.0477806 , 0.04439016, 0.04320092,\n",
       "        0.05128556, 0.05408648, 0.05253967, 0.03131937, 0.04439016,\n",
       "        0.03131937, 0.04912428, 0.03159531, 0.05448624, 0.03784563,\n",
       "        0.02124591, 0.04061164, 0.05335937, 0.03186887, 0.05103104,\n",
       "        0.03118048, 0.06305311, 0.04350128, 0.05335937, 0.03486083,\n",
       "        0.04299952, 0.04093101, 0.05527708, 0.04093101, 0.06339635,\n",
       "        0.03691676, 0.0576598 , 0.04448783, 0.02585349, 0.03267581,\n",
       "        0.04592793, 0.02825971, 0.03423266, 0.05682576, 0.03320287,\n",
       "        0.02901748, 0.06201198, 0.04166667, 0.03761556, 0.04238956,\n",
       "        0.08138344, 0.05535554, 0.03632416, 0.0389756 , 0.0463044 ,\n",
       "        0.04448783, 0.04093101, 0.0344853 , 0.04289846, 0.04399732,\n",
       "        0.00931695, 0.03267581, 0.04299952, 0.0728869 , 0.03267581,\n",
       "        0.06201198, 0.04796194, 0.025     , 0.04218428, 0.0477806 ,\n",
       "        0.05408648, 0.03807431, 0.04535738, 0.04497299, 0.04238956,\n",
       "        0.06201198, 0.06130808, 0.03159531, 0.05128556, 0.0389756 ,\n",
       "        0.04439016, 0.02083333, 0.02635231, 0.05628857, 0.04796194,\n",
       "        0.02748105, 0.02990146, 0.04930066, 0.04039733, 0.0463044 ,\n",
       "        0.01932004, 0.03864008, 0.02990146, 0.03572173, 0.05628857,\n",
       "        0.04299952, 0.05914612, 0.03131937, 0.05245699, 0.03385016,\n",
       "        0.06088183, 0.02019867, 0.05327797, 0.03761556, 0.04039733,\n",
       "        0.05311479, 0.02585349, 0.04399732, 0.04187448, 0.03227486,\n",
       "        0.04686342, 0.04299952, 0.02041241, 0.03584302, 0.0576598 ,\n",
       "        0.03047654, 0.04823265, 0.03644345, 0.0463044 , 0.04187448,\n",
       "        0.02748105, 0.04768968, 0.02748105, 0.05566829, 0.04535738,\n",
       "        0.03807431, 0.0488585 , 0.03131937, 0.025     , 0.04723243,\n",
       "        0.05286907, 0.02871677, 0.03919768, 0.04583333, 0.04093101,\n",
       "        0.0389756 , 0.0344853 , 0.03784563, 0.03254271, 0.04028975,\n",
       "        0.07113905, 0.05644257, 0.03875224, 0.03486083, 0.04114254,\n",
       "        0.0344853 , 0.05833333, 0.04238956, 0.04340139, 0.04991312,\n",
       "        0.041978  , 0.01412985, 0.03864008, 0.02684187, 0.05120086,\n",
       "        0.05      , 0.02946278, 0.05376453, 0.04686342, 0.04299952,\n",
       "        0.03186887, 0.04082483, 0.06159061, 0.06366961, 0.05368374,\n",
       "        0.03547789, 0.01976424, 0.0720484 , 0.04289846, 0.03644345,\n",
       "        0.02871677, 0.03186887, 0.05987545, 0.02083333, 0.04289846,\n",
       "        0.05204165, 0.03632416, 0.01792151, 0.03761556, 0.05245699,\n",
       "        0.01666667, 0.02224391, 0.03461093, 0.06109533, 0.06421265,\n",
       "        0.04093101, 0.04439016, 0.03584302, 0.04583333, 0.04750731,\n",
       "        0.03186887, 0.02667968, 0.03632416, 0.03333333, 0.05204165,\n",
       "        0.04439016, 0.04564355, 0.02144923, 0.04007372, 0.04320092,\n",
       "        0.04028975, 0.03131937, 0.05705443, 0.05613414, 0.03397814,\n",
       "        0.03131937, 0.02990146, 0.05527708, 0.04677072, 0.03267581,\n",
       "        0.02975595, 0.01559024, 0.06827487, 0.03547789, 0.03818813,\n",
       "        0.03397814, 0.03930825, 0.05376453, 0.01559024, 0.0463044 ,\n",
       "        0.06353313, 0.05535554, 0.0463044 , 0.03131937, 0.04611655,\n",
       "        0.05327797, 0.0497389 , 0.02901748, 0.0372678 , 0.06215181,\n",
       "        0.03875224, 0.03510896, 0.02901748, 0.02411633, 0.04487637,\n",
       "        0.04991312, 0.02990146, 0.04399732, 0.04093101, 0.03807431,\n",
       "        0.05245699, 0.04145781, 0.04135299, 0.05628857, 0.04723243,\n",
       "        0.07944032, 0.03919768, 0.04611655, 0.04439016, 0.05605677,\n",
       "        0.03186887, 0.02684187, 0.03784563, 0.04289846, 0.04028975,\n",
       "        0.04991312, 0.04135299, 0.0463044 , 0.03985651, 0.04723243,\n",
       "        0.07216878, 0.02338536, 0.03333333, 0.03644345, 0.04389856,\n",
       "        0.05043216, 0.03523236, 0.03761556, 0.04686342, 0.04796194,\n",
       "        0.03359274, 0.02716334, 0.05060399, 0.05060399, 0.05448624,\n",
       "        0.04516559, 0.03919768, 0.04956407, 0.02825971, 0.0344853 ,\n",
       "        0.05145454, 0.02585349, 0.04340139, 0.03200477, 0.05943893,\n",
       "        0.09537936, 0.04439016, 0.03807431, 0.03523236, 0.04166667,\n",
       "        0.04750731, 0.05162297, 0.03864008, 0.05613414, 0.04389856,\n",
       "        0.02990146, 0.05840769, 0.04093101, 0.04399732, 0.05162297,\n",
       "        0.04439016, 0.03131937, 0.05212498, 0.04535738, 0.04399732,\n",
       "        0.03875224, 0.05566829, 0.03461093, 0.03875224, 0.04350128,\n",
       "        0.06890765, 0.05327797, 0.03807431, 0.04399732, 0.02916667,\n",
       "        0.04399732, 0.05187458, 0.03333333, 0.03864008, 0.02975595,\n",
       "        0.01666667, 0.05128556, 0.02635231, 0.04956407, 0.04686342,\n",
       "        0.05120086, 0.02975595, 0.04093101, 0.02635231, 0.04497299,\n",
       "        0.05376453, 0.060596  , 0.02841288, 0.05327797, 0.04093101,\n",
       "        0.04249183, 0.04028975, 0.05162297, 0.02825971, 0.06130808,\n",
       "        0.03254271, 0.02375365, 0.04299952, 0.03359274, 0.05034602,\n",
       "        0.01692508, 0.04007372, 0.04497299, 0.0463044 , 0.04028975,\n",
       "        0.03267581, 0.04750731, 0.04814258, 0.04497299, 0.05327797,\n",
       "        0.01932004, 0.04686342, 0.03875224, 0.03985651, 0.03930825,\n",
       "        0.04145781, 0.0773924 , 0.03919768, 0.03864008, 0.03875224,\n",
       "        0.04135299, 0.06407732, 0.04039733, 0.05170697, 0.03584302,\n",
       "        0.05128556, 0.03644345, 0.04289846, 0.05980292, 0.03131937,\n",
       "        0.04868051, 0.03807431, 0.04611655, 0.05245699, 0.03523236,\n",
       "        0.05488308, 0.04732424, 0.05162297, 0.06373774, 0.03985651,\n",
       "        0.0477806 , 0.05212498, 0.03200477, 0.04187448, 0.03019037,\n",
       "        0.05376453, 0.04487637, 0.05170697, 0.03047654, 0.03359274,\n",
       "        0.04061164, 0.03691676, 0.04238956, 0.04039733, 0.0477806 ,\n",
       "        0.05212498, 0.06737901, 0.04516559, 0.03807431, 0.0497389 ,\n",
       "        0.02585349, 0.05229125, 0.04039733, 0.04350128, 0.03090083,\n",
       "        0.03632416, 0.06574889, 0.04299952, 0.03131937, 0.04677072,\n",
       "        0.00833333, 0.03423266, 0.02763854, 0.04912428, 0.03461093,\n",
       "        0.01792151, 0.04564355, 0.03761556, 0.04796194, 0.03159531,\n",
       "        0.06434769, 0.05103104, 0.03572173, 0.03333333, 0.03644345,\n",
       "        0.05840769, 0.02990146, 0.02338536, 0.04448783, 0.05043216,\n",
       "        0.05162297, 0.04135299, 0.03761556, 0.04389856, 0.04823265,\n",
       "        0.0344853 , 0.0844714 , 0.0497389 , 0.03320287, 0.03875224,\n",
       "        0.04061164, 0.06038074, 0.0477806 , 0.03294039, 0.03047654,\n",
       "        0.04145781, 0.041978  , 0.05034602, 0.03523236, 0.05488308,\n",
       "        0.0601647 , 0.05914612, 0.04061164, 0.03632416, 0.02429563,\n",
       "        0.04991312, 0.03523236, 0.05229125, 0.05651942, 0.0488585 ,\n",
       "        0.03118048, 0.05270463, 0.04947643, 0.02716334, 0.0375    ,\n",
       "        0.06833841, 0.05870418, 0.05103104, 0.02019867, 0.02517301,\n",
       "        0.0477806 , 0.03294039, 0.0497389 , 0.03397814, 0.03875224]),\n",
       " 'rank_test_score': array([612, 453, 357, 245, 555, 629, 608, 295, 168, 505, 168, 364, 168,\n",
       "        451, 192, 529, 245, 408, 330, 141, 168, 498,  63, 480, 245, 364,\n",
       "        280, 393, 141, 113,  18, 330, 453, 141, 219, 245, 408, 113, 168,\n",
       "         39,   4, 408, 453,  46,  46, 598, 168, 113, 192, 295, 588,  63,\n",
       "         88,  59, 330, 393, 569, 216, 295, 449, 408, 569, 555, 141, 543,\n",
       "        505,  59, 555, 141, 192, 192, 606, 295, 168, 453, 393, 192, 141,\n",
       "        113, 113, 637, 606, 596, 113, 498, 517, 295, 330, 480, 480, 408,\n",
       "        543, 219, 393, 517, 330, 330, 555, 364, 219,   8,  34, 295, 216,\n",
       "        168, 588,  80,  88, 408, 113, 449, 569,  63, 245, 162, 113, 517,\n",
       "        113,  36, 219, 453,   2,  80, 245, 364, 590, 364, 295,  30, 141,\n",
       "        576,  80, 141, 113, 113,  46,  46,  30, 192, 295, 636, 113, 364,\n",
       "        295, 364, 611,  22,  34, 109, 453, 330,  39, 113, 453, 453, 408,\n",
       "        408, 408, 219, 364, 635, 638, 590, 408, 480, 634, 245, 598, 168,\n",
       "        330, 598, 295,  88, 543, 280, 598, 219, 141, 168, 322, 583, 330,\n",
       "        245, 168,  36, 480,  63,  62, 408,   9, 598, 453, 364, 219,  88,\n",
       "        566,  18,  29, 192, 245,  88, 215, 322, 168,  46, 618, 408, 322,\n",
       "         24, 280, 555, 555, 480,   9, 113, 624, 555, 493, 192, 245, 505,\n",
       "         88,  22,   5, 408, 620, 330, 517, 141, 216, 295, 493,  15, 543,\n",
       "        280, 598, 533, 141, 245, 141, 625, 612, 330, 330, 330, 565, 590,\n",
       "        505, 408, 295, 639, 295, 453, 280,  36, 408, 620, 555, 192, 168,\n",
       "        631, 364, 393,  63, 243, 330, 113,  88, 364,  39, 598, 408, 245,\n",
       "        219, 219, 393,  24, 219, 364,  46, 113, 192, 393, 168, 109, 363,\n",
       "        330,  80, 364, 168, 608, 357, 192,  46,  88, 612, 583, 357, 168,\n",
       "        113, 533, 192, 554, 330, 322, 192, 280, 109,  30, 393, 219,  88,\n",
       "        566,  24, 280, 533, 505, 408, 408,  88, 364, 608, 579, 517, 579,\n",
       "        569, 322, 533,  46, 408, 576, 583, 243, 330, 168, 295,  46, 364,\n",
       "        219, 192, 579, 480, 408, 330, 141, 245, 295, 453, 280, 162, 529,\n",
       "        113,  46, 408,  59, 517, 162,  80, 498, 141, 295, 219, 322,  88,\n",
       "         88, 620, 533, 480, 113, 453, 364, 620, 168, 330, 245,  88, 533,\n",
       "         77, 219, 113, 322, 596,  15, 408, 330,  46, 576, 192, 330, 330,\n",
       "        453, 364, 364, 517, 364, 625, 453,  63, 453, 393, 587, 245, 364,\n",
       "        505, 295, 364, 625, 505, 393, 517, 480, 543, 498, 109, 364, 493,\n",
       "        566, 192, 408, 113, 617, 408, 408, 245, 192, 632, 543, 219, 219,\n",
       "        141, 141, 141,  39,  39, 280, 629,   2, 219, 113, 168, 505, 295,\n",
       "        192,  88, 493, 590, 113, 295, 219, 505, 612,  15, 364, 476, 364,\n",
       "         63,  63, 245, 533, 295, 393, 245,  63, 113, 245, 219,   5, 245,\n",
       "        245, 245, 517, 393, 295, 453, 408, 408,  39, 219, 295, 192, 619,\n",
       "        543, 505, 453, 408, 625, 280,  63, 141, 408, 451, 598, 245, 393,\n",
       "        245, 555, 480, 295, 280, 408, 493, 569, 408, 141,  46, 543,   9,\n",
       "        219, 113, 295, 408, 162, 168,  18, 168,  88, 245,  80,  88, 453,\n",
       "        453, 498, 168, 480, 453, 168, 533, 245, 245,  63, 555, 408,   5,\n",
       "        192,  80,  63, 295, 498, 393,  24, 113, 245, 583,  18, 408, 408,\n",
       "        453, 219, 295, 357, 476, 364, 245, 113, 330,   9, 364, 517, 476,\n",
       "        408, 590, 533, 569, 280, 357, 640, 569, 543, 408, 330, 529,  77,\n",
       "        590, 408, 295, 543, 162,  88, 245, 476, 517,   9, 219, 141,  39,\n",
       "        529, 505, 480,  88,  80,  77,  24, 543,  88,  88, 364, 280,  88,\n",
       "         30,  63, 192, 393, 330, 192, 219, 612, 322, 245, 162, 168, 408,\n",
       "        408, 364,  63, 517, 113, 533, 330, 280, 245, 579, 633, 498, 245,\n",
       "        330,  46,   1, 364, 141, 192, 453, 480, 357, 280, 245, 408, 505,\n",
       "         14, 245, 453])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 100,\n",
       " 'min_samples_leaf': 15,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando o melhor score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7291666666666666"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
